#!/usr/bin/env python3
"""
é©—è­‰å’Œä¿®æ­£ AnalysisDataset çš„ startDate, endDate, totalRecords, positiveLabels
ç¢ºä¿å®ƒå€‘æ­£ç¢ºæ¶µè“‹ç›¸é—œ AnalysisReadyData çš„æ™‚é–“ç¯„åœå’Œçµ±è¨ˆè³‡æ–™
"""

import sqlite3
import sys
import os
from datetime import datetime
from typing import List, Tuple, Dict, Any

# æ·»åŠ å¾Œç«¯è·¯å¾‘ä»¥ä¾¿å°å…¥æ¨¡çµ„
sys.path.append('/home/infowin/Git-projects/pu-in-practice/backend')

def connect_to_database():
    """é€£æ¥åˆ° SQLite è³‡æ–™åº«"""
    db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
    if not os.path.exists(db_path):
        print(f"âŒ è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨: {db_path}")
        return None

    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row  # ä½¿çµæœå¯ä»¥åƒå­—å…¸ä¸€æ¨£å­˜å–
        return conn
    except Exception as e:
        print(f"âŒ é€£æ¥è³‡æ–™åº«å¤±æ•—: {e}")
        return None

def get_analysis_datasets(conn) -> List[Dict[str, Any]]:
    """å–å¾—æ‰€æœ‰ AnalysisDataset"""
    cursor = conn.cursor()
    cursor.execute("""
        SELECT id, name, start_date, end_date, building, floor, room,
               occupant_type, total_records, positive_labels
        FROM analysis_datasets
        ORDER BY created_at
    """)

    datasets = []
    for row in cursor.fetchall():
        datasets.append({
            'id': row['id'],
            'name': row['name'],
            'start_date': row['start_date'],
            'end_date': row['end_date'],
            'building': row['building'],
            'floor': row['floor'],
            'room': row['room'],
            'occupant_type': row['occupant_type'],
            'total_records': row['total_records'],
            'positive_labels': row['positive_labels']
        })

    return datasets

def get_actual_dataset_stats(conn, dataset_id: str) -> Tuple[str, str, int, int]:
    """å–å¾—ç‰¹å®š dataset å°æ‡‰çš„ AnalysisReadyData çš„å¯¦éš›çµ±è¨ˆè³‡è¨Š"""
    cursor = conn.cursor()
    cursor.execute("""
        SELECT
            MIN(timestamp) as min_timestamp,
            MAX(timestamp) as max_timestamp,
            COUNT(*) as record_count,
            SUM(CASE WHEN is_positive_label = 1 THEN 1 ELSE 0 END) as positive_count
        FROM analysis_ready_data
        WHERE dataset_id = ?
    """, (dataset_id,))

    result = cursor.fetchone()
    if result and result['min_timestamp'] and result['max_timestamp']:
        return result['min_timestamp'], result['max_timestamp'], result['record_count'], result['positive_count']
    else:
        return None, None, 0, 0

def format_timestamp(ts):
    """æ ¼å¼åŒ–æ™‚é–“æˆ³ç‚ºå¯è®€æ ¼å¼"""
    if isinstance(ts, int):
        return datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d %H:%M:%S')
    elif isinstance(ts, str):
        return datetime.fromisoformat(ts.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')
    else:
        return str(ts)

def parse_timestamp(ts):
    """è§£ææ™‚é–“æˆ³ç‚º datetime ç‰©ä»¶"""
    if isinstance(ts, int):
        # Unix æ™‚é–“æˆ³ (æ¯«ç§’)
        return datetime.fromtimestamp(ts / 1000)
    elif isinstance(ts, str):
        # ISO æ ¼å¼
        return datetime.fromisoformat(ts.replace('Z', '+00:00'))
    else:
        return ts

def verify_dataset_stats(conn):
    """é©—è­‰æ‰€æœ‰ AnalysisDataset çš„çµ±è¨ˆè³‡æ–™"""
    print("ğŸ” é©—è­‰ AnalysisDataset çš„æ—¥æœŸç¯„åœå’Œçµ±è¨ˆè³‡æ–™...")
    print("=" * 80)

    datasets = get_analysis_datasets(conn)
    issues_found = []

    for dataset in datasets:
        dataset_id = dataset['id']
        dataset_name = dataset['name']
        dataset_start = dataset['start_date']
        dataset_end = dataset['end_date']
        dataset_total_records = dataset['total_records']
        dataset_positive_labels = dataset['positive_labels']

        print(f"\nğŸ“Š æª¢æŸ¥è³‡æ–™é›†: {dataset_name}")
        print(f"   è³‡æ–™é›† ID: {dataset_id}")
        print(f"   è³‡æ–™é›†è¨˜éŒ„çš„æ™‚é–“ç¯„åœ: {format_timestamp(dataset_start)} ~ {format_timestamp(dataset_end)}")
        print(f"   è³‡æ–™é›†è¨˜éŒ„çš„çµ±è¨ˆ: {dataset_total_records} ç¸½è¨˜éŒ„, {dataset_positive_labels} æ­£æ¨™ç±¤")

        # å–å¾—å¯¦éš›çš„è³‡æ–™çµ±è¨ˆ
        actual_start, actual_end, actual_record_count, actual_positive_count = get_actual_dataset_stats(conn, dataset_id)

        if actual_start is None or actual_end is None:
            print(f"   âš ï¸  æ²’æœ‰æ‰¾åˆ°å°æ‡‰çš„ AnalysisReadyData (è¨˜éŒ„æ•¸: {actual_record_count})")
            continue

        print(f"   å¯¦éš›è³‡æ–™çš„æ™‚é–“ç¯„åœ: {format_timestamp(actual_start)} ~ {format_timestamp(actual_end)}")
        print(f"   å¯¦éš›è³‡æ–™çš„çµ±è¨ˆ: {actual_record_count} ç¸½è¨˜éŒ„, {actual_positive_count} æ­£æ¨™ç±¤")

        # æª¢æŸ¥æ—¥æœŸç¯„åœ
        dataset_start_dt = parse_timestamp(dataset_start)
        dataset_end_dt = parse_timestamp(dataset_end)
        actual_start_dt = parse_timestamp(actual_start)
        actual_end_dt = parse_timestamp(actual_end)

        # æª¢æŸ¥æ˜¯å¦æœ‰å•é¡Œ
        start_mismatch = abs((dataset_start_dt - actual_start_dt).total_seconds()) > 60  # å…è¨±1åˆ†é˜èª¤å·®
        end_mismatch = abs((dataset_end_dt - actual_end_dt).total_seconds()) > 60
        records_mismatch = dataset_total_records != actual_record_count
        labels_mismatch = dataset_positive_labels != actual_positive_count

        has_issues = start_mismatch or end_mismatch or records_mismatch or labels_mismatch

        if has_issues:
            print(f"   âŒ ç™¼ç¾è³‡æ–™ä¸åŒ¹é…!")
            if start_mismatch:
                diff_hours = (dataset_start_dt - actual_start_dt).total_seconds() / 3600
                print(f"      é–‹å§‹æ™‚é–“å·®ç•°: {diff_hours:.2f} å°æ™‚")
            if end_mismatch:
                diff_hours = (dataset_end_dt - actual_end_dt).total_seconds() / 3600
                print(f"      çµæŸæ™‚é–“å·®ç•°: {diff_hours:.2f} å°æ™‚")
            if records_mismatch:
                print(f"      ç¸½è¨˜éŒ„æ•¸å·®ç•°: è¨˜éŒ„ {dataset_total_records} vs å¯¦éš› {actual_record_count}")
            if labels_mismatch:
                print(f"      æ­£æ¨™ç±¤æ•¸å·®ç•°: è¨˜éŒ„ {dataset_positive_labels} vs å¯¦éš› {actual_positive_count}")

            issues_found.append({
                'dataset_id': dataset_id,
                'dataset_name': dataset_name,
                'current_start': dataset_start,
                'current_end': dataset_end,
                'current_total_records': dataset_total_records,
                'current_positive_labels': dataset_positive_labels,
                'correct_start': actual_start,
                'correct_end': actual_end,
                'correct_total_records': actual_record_count,
                'correct_positive_labels': actual_positive_count
            })
        else:
            print(f"   âœ… æ‰€æœ‰è³‡æ–™éƒ½æ­£ç¢º")

    return issues_found

def fix_dataset_stats(conn, issues: List[Dict[str, Any]]):
    """ä¿®æ­£ AnalysisDataset çš„çµ±è¨ˆè³‡æ–™"""
    if not issues:
        print("\nâœ… æ²’æœ‰ç™¼ç¾éœ€è¦ä¿®æ­£çš„è³‡æ–™å•é¡Œ")
        return

    print(f"\nğŸ”§ ç™¼ç¾ {len(issues)} å€‹éœ€è¦ä¿®æ­£çš„è³‡æ–™é›†")
    print("=" * 80)

    cursor = conn.cursor()

    for issue in issues:
        dataset_id = issue['dataset_id']
        dataset_name = issue['dataset_name']

        print(f"\nä¿®æ­£è³‡æ–™é›†: {dataset_name}")
        print(f"  èˆŠçš„æ™‚é–“ç¯„åœ: {format_timestamp(issue['current_start'])} ~ {format_timestamp(issue['current_end'])}")
        print(f"  æ–°çš„æ™‚é–“ç¯„åœ: {format_timestamp(issue['correct_start'])} ~ {format_timestamp(issue['correct_end'])}")
        print(f"  èˆŠçš„çµ±è¨ˆ: {issue['current_total_records']} ç¸½è¨˜éŒ„, {issue['current_positive_labels']} æ­£æ¨™ç±¤")
        print(f"  æ–°çš„çµ±è¨ˆ: {issue['correct_total_records']} ç¸½è¨˜éŒ„, {issue['correct_positive_labels']} æ­£æ¨™ç±¤")

        try:
            # å°‡å¯¦éš›æ™‚é–“ç¯„åœè½‰æ›ç‚ºæ¯«ç§’æ™‚é–“æˆ³ (SQLite ä¸­çš„æ ¼å¼)
            def timestamp_to_ms(ts):
                if isinstance(ts, int):
                    return ts  # å·²ç¶“æ˜¯æ¯«ç§’æ™‚é–“æˆ³
                elif isinstance(ts, str):
                    dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                    return int(dt.timestamp() * 1000)
                else:
                    return ts

            correct_start_ms = timestamp_to_ms(issue['correct_start'])
            correct_end_ms = timestamp_to_ms(issue['correct_end'])

            cursor.execute("""
                UPDATE analysis_datasets
                SET start_date = ?, end_date = ?, total_records = ?, positive_labels = ?
                WHERE id = ?
            """, (
                correct_start_ms,
                correct_end_ms,
                issue['correct_total_records'],
                issue['correct_positive_labels'],
                dataset_id
            ))

            print(f"  âœ… ä¿®æ­£æˆåŠŸ")
        except Exception as e:
            print(f"  âŒ ä¿®æ­£å¤±æ•—: {e}")

    # æäº¤è®Šæ›´
    try:
        conn.commit()
        print(f"\nğŸ’¾ æ‰€æœ‰è®Šæ›´å·²ä¿å­˜åˆ°è³‡æ–™åº«")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜è®Šæ›´å¤±æ•—: {e}")
        conn.rollback()

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” AnalysisDataset å®Œæ•´è³‡æ–™é©—è­‰å·¥å…·")
    print("=" * 80)

    # é€£æ¥è³‡æ–™åº«
    conn = connect_to_database()
    if not conn:
        return

    try:
        # é©—è­‰çµ±è¨ˆè³‡æ–™
        issues = verify_dataset_stats(conn)

        # ä¿®æ­£å•é¡Œ
        if issues:
            print(f"\nâš ï¸  ç™¼ç¾ {len(issues)} å€‹è³‡æ–™å•é¡Œ:")
            for i, issue in enumerate(issues, 1):
                print(f"  {i}. {issue['dataset_name']}")
                print(f"     è¨˜éŒ„æ•¸: {issue['current_total_records']} â†’ {issue['correct_total_records']}")
                print(f"     æ­£æ¨™ç±¤: {issue['current_positive_labels']} â†’ {issue['correct_positive_labels']}")

            response = input("\nğŸ¤” æ˜¯å¦è¦ä¿®æ­£é€™äº›å•é¡Œ? (y/n): ").lower().strip()
            if response == 'y' or response == 'yes':
                fix_dataset_stats(conn, issues)
            else:
                print("ğŸ“ è·³éä¿®æ­£ï¼Œåƒ…é€²è¡Œé©—è­‰")
        else:
            print("\nğŸ‰ æ‰€æœ‰ AnalysisDataset çš„è³‡æ–™éƒ½æ˜¯æ­£ç¢ºçš„!")

    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

    finally:
        conn.close()
        print("\nğŸ”š é©—è­‰å®Œæˆ")

if __name__ == "__main__":
    main()
