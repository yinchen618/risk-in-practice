#!/usr/bin/env python3
"""
ç›´æ¥æ¸¬è©¦å€™é¸è¨ˆç®—é‚è¼¯ï¼ˆä¸é€šé HTTPï¼‰
"""

import sqlite3
import json
import random

def direct_candidate_calculation():
    """ç›´æ¥èª¿ç”¨å€™é¸è¨ˆç®—é‚è¼¯"""

    print("ğŸ§® ç›´æ¥æ¸¬è©¦å€™é¸è¨ˆç®—é‚è¼¯...")
    print("=" * 60)

    # æ¸¬è©¦åƒæ•¸ï¼ˆèˆ‡ API æ¸¬è©¦ç›¸åŒï¼‰
    filter_params = {
        "selectedDatasetIds": [],
        "buildings": ["Building-A"],
        "floors": ["2F", "3F"],
        "rooms": [],
        "occupantTypes": ["STUDENT"],
        "zScoreThreshold": 2.5,
        "spikeThreshold": 200,
        "minEventDuration": 30,
        "startDate": "2025-08-01",
        "startTime": "00:00",
        "endDate": "2025-08-25",
        "endTime": "23:59",
        "random_seed": 42
    }

    results = []

    for run in range(5):
        print(f"\næ¸¬è©¦ {run+1}:")

        # æå–éæ¿¾åƒæ•¸ï¼ˆæ¨¡æ“¬ API ä¸­çš„é‚è¼¯ï¼‰
        selected_dataset_ids = filter_params.get("selectedDatasetIds", [])
        buildings = filter_params.get("buildings", [])
        floors = filter_params.get("floors", [])
        rooms = filter_params.get("rooms", [])
        occupant_types = filter_params.get("occupantTypes", [])

        # ç•°å¸¸æª¢æ¸¬åƒæ•¸
        z_score_threshold = filter_params.get("zScoreThreshold", 2.5)
        spike_threshold = filter_params.get("spikeThreshold", 200)

        # è¨­ç½®éš¨æ©Ÿç¨®å­
        seed = filter_params.get("random_seed")
        if seed is not None:
            random.seed(seed)
            print(f"  è¨­ç½®éš¨æ©Ÿç¨®å­: {seed}")

        # é€£æ¥åˆ°ä¸»è³‡æ–™åº«
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # å»ºç«‹åŸºç¤æŸ¥è©¢æ¢ä»¶
        where_conditions = []
        params = []

        # è³‡æ–™é›†éæ¿¾
        if selected_dataset_ids:
            placeholders = ','.join(['?' for _ in selected_dataset_ids])
            where_conditions.append(f"id IN ({placeholders})")
            params.extend(selected_dataset_ids)

        # å»ºç¯‰ç‰©éæ¿¾
        if buildings:
            placeholders = ','.join(['?' for _ in buildings])
            where_conditions.append(f"building IN ({placeholders})")
            params.extend(buildings)

        # æ¨“å±¤éæ¿¾
        if floors:
            placeholders = ','.join(['?' for _ in floors])
            where_conditions.append(f"floor IN ({placeholders})")
            params.extend(floors)

        # æˆ¿é–“éæ¿¾
        if rooms:
            placeholders = ','.join(['?' for _ in rooms])
            where_conditions.append(f"room IN ({placeholders})")
            params.extend(rooms)

        # ä½”ç”¨è€…é¡å‹éæ¿¾
        if occupant_types:
            placeholders = ','.join(['?' for _ in occupant_types])
            where_conditions.append(f"occupant_type IN ({placeholders})")
            params.extend(occupant_types)

        # æ§‹å»ºæŸ¥è©¢
        base_query = "SELECT * FROM analysis_datasets"
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)

        print(f"  æŸ¥è©¢: {base_query}")
        print(f"  åƒæ•¸: {params}")

        cursor.execute(base_query, params)
        filtered_datasets = cursor.fetchall()

        print(f"  æ‰¾åˆ°è³‡æ–™é›†: {len(filtered_datasets)}")

        # æ¨¡æ“¬ç•°å¸¸å€™é¸ç”Ÿæˆ
        total_candidates = 0

        if filtered_datasets:
            # åŸºæ–¼è³‡æ–™é›†æ•¸é‡å’Œåƒæ•¸æ¨¡æ“¬å€™é¸ç”Ÿæˆ
            base_candidates_per_dataset = 50  # åŸºç¤å€™é¸æ•¸

            for dataset in filtered_datasets:
                # æ ¹æ“š total_records èª¿æ•´å€™é¸æ•¸é‡
                total_records = dataset[11] if dataset[11] else 1000  # total_records æ¬„ä½æ˜¯ç´¢å¼• 11

                # æ ¹æ“šé–¾å€¼èª¿æ•´å€™é¸æ•¸é‡ï¼ˆé–¾å€¼è¶Šä½ï¼Œå€™é¸è¶Šå¤šï¼‰
                threshold_factor = max(0.1, min(2.0, 3.0 / z_score_threshold))
                spike_factor = max(0.5, min(1.5, spike_threshold / 200))

                # è¨ˆç®—å€™é¸æ•¸é‡
                dataset_candidates = int(
                    (total_records / 1000) * base_candidates_per_dataset *
                    threshold_factor * spike_factor
                )

                total_candidates += max(0, dataset_candidates)

        print(f"  ç¸½å€™é¸æ•¸é‡: {total_candidates}")
        results.append(total_candidates)

        conn.close()

    # åˆ†æçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š çµæœåˆ†æ:")

    unique_counts = set(results)

    if len(unique_counts) == 1:
        print(f"âœ… æ‰€æœ‰æ¸¬è©¦çµæœä¸€è‡´: {list(unique_counts)[0]} å€‹å€™é¸")
        print("ğŸ¯ é‚è¼¯ç¢ºå¯¦æ˜¯ç¢ºå®šæ€§çš„ï¼")
        return True
    else:
        print(f"âŒ çµæœä¸ä¸€è‡´: {unique_counts}")
        print(f"ğŸ“ˆ æœ€å°å€¼: {min(results)}")
        print(f"ğŸ“ˆ æœ€å¤§å€¼: {max(results)}")
        print(f"ğŸ“ˆ å¹³å‡å€¼: {sum(results) / len(results):.1f}")
        return False

if __name__ == "__main__":
    direct_candidate_calculation()
