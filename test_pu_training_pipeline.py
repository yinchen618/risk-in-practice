#!/usr/bin/env python3
"""
æ¸¬è©¦ PU Learning è¨“ç·´ç®¡ç·šçš„å®Œæ•´åŠŸèƒ½
Test complete PU Learning training pipeline functionality
"""

import json
import sqlite3
from datetime import datetime, timedelta
import numpy as np

def test_data_source_extraction():
    """æ¸¬è©¦æ•¸æ“šæºæå–åŠŸèƒ½"""
    print("ğŸ§ª Testing data source extraction functionality")

    # æ¨¡æ“¬å‰ç«¯é…ç½®
    mock_data_source_config = {
        "trainRatio": 60,
        "validationRatio": 25,
        "testRatio": 15,
        "timeRange": "recent",
        "positiveDataSourceIds": [1, 2, 3],
        "unlabeledDataSourceIds": [4, 5, 6, 7]
    }

    # æ¸¬è©¦æ¯”ä¾‹æ­£è¦åŒ–
    train_ratio_raw = mock_data_source_config.get("trainRatio", 70)
    validation_ratio_raw = mock_data_source_config.get("validationRatio", 20)
    test_ratio_raw = mock_data_source_config.get("testRatio", 10)

    total_ratio = train_ratio_raw + validation_ratio_raw + test_ratio_raw
    train_ratio = train_ratio_raw / total_ratio
    validation_ratio = validation_ratio_raw / total_ratio
    test_ratio = test_ratio_raw / total_ratio

    print(f"âœ… Original ratios: Train={train_ratio_raw}%, Val={validation_ratio_raw}%, Test={test_ratio_raw}%")
    print(f"âœ… Normalized ratios: Train={train_ratio:.1%}, Val={validation_ratio:.1%}, Test={test_ratio:.1%}")
    print(f"âœ… Sum check: {train_ratio + validation_ratio + test_ratio:.3f} (should be 1.000)")

    # é©—è­‰æ¯”ä¾‹ç¸½å’Œ
    assert abs((train_ratio + validation_ratio + test_ratio) - 1.0) < 0.001, "Ratios should sum to 1.0"

    return mock_data_source_config

def test_data_overlap_removal():
    """æ¸¬è©¦æ•¸æ“šé‡ç–Šç§»é™¤åŠŸèƒ½"""
    print("\nğŸ§ª Testing data overlap removal functionality")

    # æ¨¡æ“¬ P å’Œ U æ•¸æ“šæ¨£æœ¬
    p_samples = [
        (1, 1, "2024-01-01T10:00:00Z", "room1", 100, 150, 110, 220, 330, True),
        (2, 1, "2024-01-01T10:15:00Z", "room1", 105, 155, 115, 225, 340, True),
        (3, 1, "2024-01-01T10:30:00Z", "room1", 110, 160, 120, 230, 350, True),
    ]

    # U æ•¸æ“šåŒ…å«èˆ‡ P é‡ç–Šçš„æ¨£æœ¬
    u_samples_with_overlap = [
        (1, 1, "2024-01-01T10:00:00Z", "room1", 100, 150, 110, 220, 330, False),  # é‡ç–Š
        (2, 1, "2024-01-01T10:15:00Z", "room1", 105, 155, 115, 225, 340, False),  # é‡ç–Š
        (4, 1, "2024-01-01T11:00:00Z", "room1", 120, 170, 130, 240, 370, False),  # ä¸é‡ç–Š
        (5, 1, "2024-01-01T11:15:00Z", "room1", 125, 175, 135, 245, 380, False),  # ä¸é‡ç–Š
        (6, 1, "2024-01-01T11:30:00Z", "room1", 130, 180, 140, 250, 390, False),  # ä¸é‡ç–Š
    ]

    # æå– P æ¨£æœ¬çš„ ID
    p_sample_ids = {sample[0] for sample in p_samples}
    print(f"ğŸ“Š P sample IDs: {p_sample_ids}")

    # å¾ U æ¨£æœ¬ä¸­ç§»é™¤é‡ç–Šçš„æ¨£æœ¬
    u_samples_filtered = [sample for sample in u_samples_with_overlap if sample[0] not in p_sample_ids]

    print(f"ğŸ“Š Original U samples: {len(u_samples_with_overlap)}")
    print(f"ğŸ“Š Filtered U samples: {len(u_samples_filtered)} (removed {len(u_samples_with_overlap) - len(u_samples_filtered)} overlapping)")

    # é©—è­‰æ²’æœ‰é‡ç–Š
    u_filtered_ids = {sample[0] for sample in u_samples_filtered}
    overlap_check = p_sample_ids.intersection(u_filtered_ids)
    assert len(overlap_check) == 0, f"Still have overlapping IDs: {overlap_check}"

    print("âœ… Overlap removal successful")
    return p_samples, u_samples_filtered

def test_u_data_limit():
    """æ¸¬è©¦ U æ•¸æ“š 10 å€é™åˆ¶åŠŸèƒ½"""
    print("\nğŸ§ª Testing U data 10x limit functionality")

    p_samples = [(i, 1, f"2024-01-01T10:{i:02d}:00Z", "room1", 100+i, 150+i, 110+i, 220+i, 330+i, True) for i in range(5)]

    # å‰µå»ºè¶…é 10 å€çš„ U æ•¸æ“š
    u_samples_large = [(i+100, 1, f"2024-01-01T11:{i:02d}:00Z", "room1", 200+i, 250+i, 210+i, 320+i, 530+i, False) for i in range(60)]

    max_unlabeled_samples = len(p_samples) * 10

    print(f"ğŸ“Š P samples: {len(p_samples)}")
    print(f"ğŸ“Š Original U samples: {len(u_samples_large)}")
    print(f"ğŸ“Š Max allowed U samples (10x P): {max_unlabeled_samples}")

    if len(u_samples_large) > max_unlabeled_samples:
        print(f"ğŸ“Š Randomly sampling {max_unlabeled_samples} from {len(u_samples_large)} available U samples")
        import random
        random.seed(42)  # For reproducibility
        u_samples_limited = random.sample(u_samples_large, max_unlabeled_samples)
    else:
        u_samples_limited = u_samples_large

    print(f"ğŸ“Š Final U samples: {len(u_samples_limited)}")

    # é©—è­‰é™åˆ¶
    assert len(u_samples_limited) <= max_unlabeled_samples, f"U samples exceed 10x limit: {len(u_samples_limited)} > {max_unlabeled_samples}"

    print("âœ… U data 10x limit test successful")
    return p_samples, u_samples_limited

def test_data_splitting():
    """æ¸¬è©¦æ•¸æ“šåˆ†å‰²åŠŸèƒ½"""
    print("\nğŸ§ª Testing data splitting functionality")

    # å‰µå»ºæ¨¡æ“¬ç‰¹å¾µçŸ©é™£å’Œæ¨™ç±¤
    np.random.seed(42)
    n_samples = 1000
    n_features = 24  # å¤šå°ºåº¦ç‰¹å¾µ

    X = np.random.randn(n_samples, n_features)
    y = np.random.randint(0, 2, n_samples)  # 0: unlabeled, 1: positive

    # æ•¸æ“šåˆ†å‰²æ¯”ä¾‹
    train_ratio = 0.6
    validation_ratio = 0.25
    test_ratio = 0.15

    # è¨ˆç®—åˆ†å‰²ç´¢å¼•
    total_samples = X.shape[0]
    train_end = int(total_samples * train_ratio)
    val_end = train_end + int(total_samples * validation_ratio)

    # åˆ†å‰²æ•¸æ“š
    X_train_split = X[:train_end]
    X_val_split = X[train_end:val_end]
    X_test_split = X[val_end:]

    y_train_split = y[:train_end]
    y_val_split = y[train_end:val_end]
    y_test_split = y[val_end:]

    print(f"ğŸ“Š Data split results:")
    print(f"   - Train: {X_train_split.shape[0]} samples ({X_train_split.shape[0]/total_samples:.1%})")
    print(f"   - Validation: {X_val_split.shape[0]} samples ({X_val_split.shape[0]/total_samples:.1%})")
    print(f"   - Test: {X_test_split.shape[0]} samples ({X_test_split.shape[0]/total_samples:.1%})")

    # é©—è­‰åˆ†å‰²
    total_split = X_train_split.shape[0] + X_val_split.shape[0] + X_test_split.shape[0]
    assert total_split == total_samples, f"Split samples don't match total: {total_split} != {total_samples}"

    print("âœ… Data splitting test successful")
    return X_train_split, X_val_split, X_test_split, y_train_split, y_val_split, y_test_split

def main():
    """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("ğŸ§ª Testing PU Learning Training Pipeline")
    print("=" * 50)

    try:
        # æ¸¬è©¦ 1: æ•¸æ“šæºé…ç½®æå–
        data_source_config = test_data_source_extraction()

        # æ¸¬è©¦ 2: æ•¸æ“šé‡ç–Šç§»é™¤
        p_samples, u_samples = test_data_overlap_removal()

        # æ¸¬è©¦ 3: U æ•¸æ“š 10 å€é™åˆ¶
        p_samples_limited, u_samples_limited = test_u_data_limit()

        # æ¸¬è©¦ 4: æ•¸æ“šåˆ†å‰²
        X_train, X_val, X_test, y_train, y_val, y_test = test_data_splitting()

        print("\n" + "=" * 50)
        print("ğŸ‰ All tests passed successfully!")
        print("âœ… PU Learning training pipeline is ready")

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
