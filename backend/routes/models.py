"""
æ¨¡å‹è¨“ç·´ API è·¯ç”± - è™•ç† PU Learning æ¨¡å‹è¨“ç·´
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, Optional, Any, List
import logging
import uuid
from datetime import datetime

from services.training_service import training_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/models", tags=["Model Training"])

# Pydantic æ¨¡å‹
class ModelTrainingRequest(BaseModel):
    model_name: str
    model_type: str  # "uPU" or "nnPU"
    activation: Optional[str] = "relu"
    n_epochs: Optional[int] = 100
    n_estimators: Optional[int] = 100  # for nnPU RandomForest

class ModelTrainingResponse(BaseModel):
    success: bool
    task_id: str
    message: str
    estimated_completion_time: str

class ModelResultsResponse(BaseModel):
    success: bool
    data: Optional[Dict[str, Any]] = None
    message: str

class TaskStatusResponse(BaseModel):
    success: bool
    task_id: str
    status: str  # "pending", "running", "completed", "failed"
    progress: Optional[float] = None
    message: str
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None

class TrainAndPredictRequest(BaseModel):
    experiment_run_id: str
    model_params: Dict[str, Any]
    prediction_start_date: str
    prediction_end_date: str

class JobStatusResponse(BaseModel):
    status: str
    progress: float
    model_id: Optional[str] = None
    error: Optional[str] = None
    message: Optional[str] = None

class PredictOnlyRequest(BaseModel):
    model_id: str
    prediction_start_date: str
    prediction_end_date: str
    time_range: Optional[Dict[str, str]] = None
    floor_selection: Optional[Dict[str, Any]] = None

# å…¨åŸŸè¨“ç·´ä»»å‹™è¿½è¹¤
training_tasks: Dict[str, Dict[str, Any]] = {}
job_tasks: Dict[str, Dict[str, Any]] = {}

@router.post("/train", response_model=ModelTrainingResponse)
async def train_model(
    request: ModelTrainingRequest,
    background_tasks: BackgroundTasks
):
    """
    è§¸ç™¼æ¨¡å‹è¨“ç·´ï¼ˆå°æ‡‰ "é–‹å§‹è¨“ç·´" æŒ‰éˆ•ï¼‰
    ä½¿ç”¨èƒŒæ™¯ä»»å‹™é€²è¡Œç•°æ­¥è™•ç†
    """
    try:
        logger.info(f"é–‹å§‹è¨“ç·´ {request.model_type} æ¨¡å‹: {request.model_name}")

        # é©—è­‰æ¨¡å‹é¡å‹
        if request.model_type.lower() not in ['upu', 'nnpu']:
            raise HTTPException(status_code=400, detail="æ¨¡å‹é¡å‹å¿…é ˆæ˜¯ 'uPU' æˆ– 'nnPU'")

        # ç”Ÿæˆä»»å‹™ID
        task_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        training_tasks[task_id] = {
            'status': 'pending',
            'progress': 0.0,
            'message': 'æ­£åœ¨æº–å‚™æ¨¡å‹è¨“ç·´...',
            'start_time': datetime.utcnow(),
            'result': None,
            'error': None,
            'model_name': request.model_name,
            'model_type': request.model_type
        }

        # æº–å‚™æ¨¡å‹åƒæ•¸
        model_params = {
            'activation': request.activation,
            'n_epochs': request.n_epochs,
            'n_estimators': request.n_estimators
        }

        # å•Ÿå‹•èƒŒæ™¯ä»»å‹™
        background_tasks.add_task(
            _train_model_background,
            task_id,
            request.model_name,
            request.model_type,
            model_params
        )

        estimated_time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')

        return ModelTrainingResponse(
            success=True,
            task_id=task_id,
            message=f"{request.model_type} æ¨¡å‹è¨“ç·´ä»»å‹™å·²å•Ÿå‹•",
            estimated_completion_time=estimated_time
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å•Ÿå‹•æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å•Ÿå‹•è¨“ç·´å¤±æ•—: {str(e)}")

@router.get("/jobs/{job_id}")
async def get_job_status(job_id: str):
    task = job_tasks.get(job_id)
    if not task:
        raise HTTPException(status_code=404, detail="Job not found")
    return {
        'status': task['status'],
        'progress': task.get('progress', 0.0),
        'model_id': task.get('model_id'),
        'error': task.get('error'),
        'message': task.get('message'),
    }


@router.get("/{model_id}/results")
async def get_model_results(model_id: str):
    # å›å‚³ç°¡åŒ–çµæœèˆ‡ artifacts
    from core.database import db_manager
    from sqlalchemy import text
    async with db_manager.get_session() as session:
        # Try the new table first (trained_models)
        q = text("SELECT * FROM trained_models WHERE id = :id")
        r = await session.execute(q, {"id": model_id})
        row = r.first()

        if not row:
            # Fallback to old table (trained_model)
            q = text("SELECT * FROM trained_model WHERE id = :id")
            r = await session.execute(q, {"id": model_id})
            row = r.first()

        if not row:
            raise HTTPException(status_code=404, detail="Model not found")

        # Handle both old and new schema
        if hasattr(row, 'training_metrics') and row.training_metrics:
            # New schema with training_metrics JSON field
            import json
            try:
                if isinstance(row.training_metrics, str):
                    all_metrics = json.loads(row.training_metrics)
                else:
                    all_metrics = row.training_metrics

                metrics = {}
                # Include test set metrics if available
                if 'test_metrics' in all_metrics:
                    metrics['test_metrics'] = all_metrics['test_metrics']
                if 'test_sample_count' in all_metrics:
                    metrics['test_sample_count'] = all_metrics['test_sample_count']

                # Include validation metrics
                if 'val_precision' in all_metrics:
                    metrics['precision'] = all_metrics['val_precision']
                if 'val_recall' in all_metrics:
                    metrics['recall'] = all_metrics['val_recall']
                if 'val_f1' in all_metrics:
                    metrics['f1'] = all_metrics['val_f1']

            except Exception as e:
                print(f"Error parsing training_metrics: {e}")
                metrics = {}
        else:
            # Old schema with separate precision, recall, f1Score fields
            metrics = {
                'precision': float(row.precision) if hasattr(row, 'precision') and row.precision else 0.0,
                'recall': float(row.recall) if hasattr(row, 'recall') and row.recall else 0.0,
                'f1': float(row.f1Score) if hasattr(row, 'f1Score') and row.f1Score else 0.0,
            }

        # Determine table structure for response
        model_name = getattr(row, 'modelName', None) or getattr(row, 'model_type', 'Unknown Model')
        model_type = getattr(row, 'modelType', None) or getattr(row, 'model_type', 'Unknown')
        created_at = getattr(row, 'createdAt', None) or getattr(row, 'created_at', None)
        updated_at = getattr(row, 'updatedAt', None) or getattr(row, 'completed_at', None)
        model_path = getattr(row, 'modelPath', None) or getattr(row, 'model_path', None)

        return {
            'meta': {
                'model_id': row.id,
                'model_name': model_name,
                'model_type': model_type,
                'created_at': created_at.isoformat() if created_at else None,
                'updated_at': updated_at.isoformat() if updated_at else None,
            },
            'metrics': metrics,
            'artifacts': {
                'model_path': model_path,
            },
        }


@router.get("/{model_id}/predictions")
async def get_model_predictions(model_id: str, limit: int = 1000):
    """å›å‚³å„²å­˜åœ¨ model_prediction çš„é€é»çµæœï¼Œä¾›å‰ç«¯ç¹ªåœ–ã€‚"""
    try:
        from core.database import db_manager
        from sqlalchemy import text
        async with db_manager.get_session() as session:
            q = text(
                """
                SELECT timestamp, "predictionScore", "groundTruth"
                FROM model_prediction
                WHERE "trainedModelId" = :mid
                ORDER BY timestamp ASC
                LIMIT :lim
                """
            )
            res = await session.execute(q, {"mid": model_id, "lim": limit})
            rows = res.fetchall()
            data = [
                {
                    "timestamp": r.timestamp.isoformat() if r.timestamp else None,
                    "predictionScore": float(r.predictionScore),
                    "groundTruth": int(r.groundTruth) if r.groundTruth is not None else None,
                }
                for r in rows
            ]
        return {"success": True, "data": data}
    except Exception as e:
        logger.error(f"Failed to get predictions for model {model_id}: {e}")
        raise HTTPException(status_code=500, detail="Failed to fetch model predictions")


@router.post("/{model_id}/predict")
async def predict_only(model_id: str, request: PredictOnlyRequest, background_tasks: BackgroundTasks):
    try:
        job_id = str(uuid.uuid4())
        job_tasks[job_id] = {
            'status': 'QUEUED',
            'progress': 0.0,
            'message': 'Queued',
            'result': None,
            'error': None,
        }
        background_tasks.add_task(_predict_only_bg, job_id, model_id, request.dict())
        return {"job_id": job_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def _train_and_predict_bg(job_id: str, payload: Dict[str, Any]):
    try:
        job_tasks[job_id]['status'] = 'RUNNING'
        job_tasks[job_id]['progress'] = 0.05
        job_tasks[job_id]['message'] = 'Preparing training data'

        run_id = payload['experiment_run_id']
        params = payload['model_params']
        start_date = payload['prediction_start_date']
        end_date = payload['prediction_end_date']

        # 1) æº–å‚™è¨“ç·´è³‡æ–™
        X, y, summary = await training_service.prepare_training_data_for_experiment_run(run_id)

        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        labeled_mask = y != 0
        X_labeled = X_scaled[labeled_mask]
        y_binary = (y[labeled_mask] == 1).astype(int)

        job_tasks[job_id]['progress'] = 0.25
        job_tasks[job_id]['message'] = 'Training model'

        # 2) è¨“ç·´ï¼ˆæ²¿ç”¨ç¾æœ‰ç°¡åŒ– uPU/nnPUï¼‰
        model_type = (params.get('model_type') or 'nnPU').lower()
        if model_type == 'upu':
            model, metrics = await training_service._train_upu_model(X_scaled, y, X_labeled, y_binary, params)
        else:
            model, metrics = await training_service._train_nnpu_model(X_scaled, y, X_labeled, y_binary, params)

        # 3) å„²å­˜æ¨¡å‹
        import joblib, os
        from datetime import datetime
        artifacts_dir = os.path.join(os.path.dirname(__file__), '..', 'trained_models')
        os.makedirs(artifacts_dir, exist_ok=True)
        model_path = os.path.abspath(os.path.join(artifacts_dir, f"pu_model_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.joblib"))
        joblib.dump({'model': model, 'scaler': scaler, 'data_summary': summary, 'training_params': params}, model_path)

        # 4) è¨˜éŒ„åˆ° trained_model è¡¨
        model_id = await training_service._save_model_to_database(
            model_name=params.get('model_name', 'pu_model'),
            model_type=params.get('model_type', 'nnPU'),
            model_path=model_path,
            metrics=metrics,
            data_summary=summary,
            experiment_run_id=run_id
        )

        job_tasks[job_id]['progress'] = 0.6
        job_tasks[job_id]['message'] = 'Predicting on timerange'

        # 5) æ´©æ¼é˜²è­·ï¼šæ’é™¤è¨“ç·´äº‹ä»¶æ™‚é–“çª—
        from sqlalchemy import text
        from core.database import db_manager
        exclude_windows: list = []
        async with db_manager.get_session() as session:
            q = text('''
                SELECT "meterId" as meter_id, MIN("eventTimestamp") as min_ts, MAX("eventTimestamp") as max_ts
                FROM anomaly_event
                WHERE "experimentRunId" = :rid
                GROUP BY "meterId"
            ''')
            res = await session.execute(q, {"rid": run_id})
            for row in res:
                exclude_windows.append((row.meter_id, row.min_ts, row.max_ts))

        # 6) é æ¸¬
        pred = await training_service.predict_on_timerange(model_path, start_date, end_date, exclude_windows)

        job_tasks[job_id]['status'] = 'SUCCEEDED'
        job_tasks[job_id]['progress'] = 1.0
        job_tasks[job_id]['message'] = 'Completed'
        # å°‡é€é»é æ¸¬å¯«å…¥ model_prediction ä¾› Stage 4 åœ–è¡¨æŸ¥è©¢
        try:
            from core.database import db_manager
            from sqlalchemy import text
            rows = [
                {
                    "id": str(uuid.uuid4()),
                    "trainedModelId": model_id,
                    "timestamp": p.get('window_start_ts') or p.get('timestamp') or datetime.utcnow(),
                    "predictionScore": float(p.get('score')) if p.get('score') is not None else float(p.get('predictionScore', 0.0)),
                    "groundTruth": p.get('y_true') if p.get('y_true') is not None else None,
                }
                for p in pred.get('predictions', [])
            ]
            if rows:
                async with db_manager.get_session() as session:
                    insert_sql = text(
                        'INSERT INTO model_prediction (id, "trainedModelId", timestamp, "predictionScore", "groundTruth")\n'
                        'VALUES (:id, :trainedModelId, :timestamp, :predictionScore, :groundTruth)'
                    )
                    await session.execute(insert_sql, rows)
                    await session.commit()
        except Exception as e:
            logger.warning(f"Failed to persist model predictions for model {model_id}: {e}")

        job_tasks[job_id]['result'] = {
            'model_id': model_id,
            'predictions_topk': pred['predictions']
        }
        job_tasks[job_id]['model_id'] = model_id
    except Exception as e:
        job_tasks[job_id]['status'] = 'FAILED'
        job_tasks[job_id]['error'] = str(e)
        job_tasks[job_id]['message'] = 'Failed'
        job_tasks[job_id]['progress'] = 0.0


async def _predict_only_bg(job_id: str, model_id: str, payload: Dict[str, Any]):
    try:
        job_tasks[job_id]['status'] = 'RUNNING'
        job_tasks[job_id]['progress'] = 0.1
        job_tasks[job_id]['message'] = 'Loading model'

        # å–å¾—æ¨¡å‹ artifact è·¯å¾‘
        from core.database import db_manager
        from sqlalchemy import text
        async with db_manager.get_session() as session:
            q = text("SELECT \"modelPath\" FROM trained_model WHERE id = :id")
            r = await session.execute(q, {"id": model_id})
            row = r.first()
            if not row:
                raise ValueError("Model not found")
            model_path = row.modelPath

        job_tasks[job_id]['progress'] = 0.4
        job_tasks[job_id]['message'] = 'Predicting'

        pred = await training_service.predict_on_timerange(
            model_path,
            payload['prediction_start_date'],
            payload['prediction_end_date'],
            exclude_windows=None,
        )

        job_tasks[job_id]['status'] = 'SUCCEEDED'
        job_tasks[job_id]['progress'] = 1.0
        job_tasks[job_id]['message'] = 'Completed'
        job_tasks[job_id]['result'] = {'predictions_topk': pred['predictions']}
    except Exception as e:
        job_tasks[job_id]['status'] = 'FAILED'
        job_tasks[job_id]['error'] = str(e)
        job_tasks[job_id]['message'] = 'Failed'
        job_tasks[job_id]['progress'] = 0.0

@router.get("/train/{task_id}/status", response_model=TaskStatusResponse)
async def get_training_status(task_id: str):
    """ç²å–æ¨¡å‹è¨“ç·´ä»»å‹™ç‹€æ…‹"""
    if task_id not in training_tasks:
        raise HTTPException(status_code=404, detail="è¨“ç·´ä»»å‹™ä¸å­˜åœ¨")

    task_info = training_tasks[task_id]

    return TaskStatusResponse(
        success=True,
        task_id=task_id,
        status=task_info['status'],
        progress=task_info.get('progress'),
        message=task_info['message'],
        result=task_info.get('result'),
        error=task_info.get('error')
    )

@router.get("/latest/results", response_model=ModelResultsResponse)
async def get_latest_model_results():
    """
    ç²å–æœ€æ–°è¨“ç·´æˆæœï¼ˆå°æ‡‰ "Results & Insights" é é¢è¼‰å…¥ï¼‰
    """
    try:
        logger.info("ç²å–æœ€æ–°æ¨¡å‹çµæœ")

        # å¾è³‡æ–™åº«ç²å–æœ€æ–°æ¨¡å‹çµæœ
        latest_result = await training_service.get_latest_model_results()

        if not latest_result:
            return ModelResultsResponse(
                success=True,
                data=None,
                message="å°šæœªæœ‰å·²è¨“ç·´çš„æ¨¡å‹"
            )

        # å¢å¼·çµæœæ•¸æ“š
        enhanced_result = {
            **latest_result,
            'performance_insights': _generate_performance_insights(latest_result),
            'recommendations': _generate_recommendations(latest_result)
        }

        return ModelResultsResponse(
            success=True,
            data=enhanced_result,
            message="æˆåŠŸç²å–æœ€æ–°æ¨¡å‹çµæœ"
        )

    except Exception as e:
        logger.error(f"ç²å–æ¨¡å‹çµæœå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–çµæœå¤±æ•—: {str(e)}")

@router.get("/all", response_model=ModelResultsResponse)
async def get_all_models():
    """ç²å–æ‰€æœ‰å·²è¨“ç·´çš„æ¨¡å‹"""
    try:
        # é€™è£¡å¯ä»¥å¯¦ç¾ç²å–æ‰€æœ‰æ¨¡å‹çš„é‚è¼¯
        # æš«æ™‚è¿”å›æœ€æ–°æ¨¡å‹
        latest_result = await training_service.get_latest_model_results()

        models_list = []
        if latest_result:
            models_list.append(latest_result)

        return ModelResultsResponse(
            success=True,
            data={'models': models_list, 'total': len(models_list)},
            message=f"æˆåŠŸç²å– {len(models_list)} å€‹æ¨¡å‹"
        )

    except Exception as e:
        logger.error(f"ç²å–æ‰€æœ‰æ¨¡å‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)}")

@router.get("/experiment/{experiment_run_id}", response_model=ModelResultsResponse)
async def get_all_models_by_experiment(experiment_run_id: str):
    """ç²å–ç‰¹å®šå¯¦é©—çš„æ‰€æœ‰å·²è¨“ç·´æ¨¡å‹ï¼ˆä¸åˆ†æƒ…å¢ƒé¡å‹ï¼‰"""
    try:
        from database import db_manager

        # ç²å–è©²å¯¦é©—çš„æ‰€æœ‰æ¨¡å‹ï¼Œä¸é™åˆ¶ scenario_type
        models = await db_manager.get_all_trained_models_by_experiment(experiment_run_id)
        
        logger.info(f"ğŸ” ç²å–å¯¦é©— {experiment_run_id} çš„æ‰€æœ‰æ¨¡å‹: {len(models)} å€‹")

        models_list = []
        for model in models:
            # model.model_config æ˜¯å­—å…¸ï¼Œéœ€è¦ç”¨å­—å…¸æ–¹å¼è¨ªå•
            model_config = model.model_config or {}
            model_type = model_config.get('model_type', 'Unknown')

            model_data = {
                'id': model.id,
                'scenario_type': model.scenario_type,
                'model_name': f"{model_type}_{model.id[:8]}",  # ç”Ÿæˆæ¨¡å‹åç¨±
                'model_type': model_type,
                'status': model.status,
                'created_at': model.created_at.isoformat() if model.created_at else None,
                'updated_at': model.completed_at.isoformat() if model.completed_at else None,
                'metrics': model.training_metrics,
                'training_params': model.model_config
            }
            models_list.append(model_data)
            
        logger.info(f"ğŸ” è½‰æ›å¾Œçš„æ¨¡å‹åˆ—è¡¨: {models_list}")

        return ModelResultsResponse(
            success=True,
            data={'models': models_list, 'total': len(models_list)},
            message=f"æˆåŠŸç²å–å¯¦é©— {experiment_run_id} çš„ {len(models_list)} å€‹æ¨¡å‹"
        )

    except Exception as e:
        logger.error(f"ç²å–å¯¦é©—æ‰€æœ‰æ¨¡å‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–å¯¦é©—æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)}")

@router.get("/experiment/{experiment_run_id}/{scenario_type}", response_model=ModelResultsResponse)
async def get_models_by_experiment(experiment_run_id: str, scenario_type: str):
    """ç²å–ç‰¹å®šå¯¦é©—çš„æ‰€æœ‰å·²è¨“ç·´æ¨¡å‹"""
    try:
        from database import db_manager

        models = await db_manager.get_trained_models_by_experiment(experiment_run_id, scenario_type)

        models_list = []
        for model in models:
            # model.model_config æ˜¯å­—å…¸ï¼Œéœ€è¦ç”¨å­—å…¸æ–¹å¼è¨ªå•
            model_config = model.model_config or {}
            model_type = model_config.get('model_type', 'Unknown')

            model_data = {
                'id': model.id,
                'scenario_type': model.scenario_type,
                'model_name': f"{model_type}_{model.id[:8]}",  # ç”Ÿæˆæ¨¡å‹åç¨±
                'model_type': model_type,
                'status': model.status,
                'created_at': model.created_at.isoformat() if model.created_at else None,
                'updated_at': model.completed_at.isoformat() if model.completed_at else None,
                'metrics': model.training_metrics,
                'training_params': model.model_config
            }
            models_list.append(model_data)

        return ModelResultsResponse(
            success=True,
            data={'models': models_list, 'total': len(models_list)},
            message=f"æˆåŠŸç²å–å¯¦é©— {experiment_run_id} çš„ {len(models_list)} å€‹æ¨¡å‹"
        )

    except Exception as e:
        logger.error(f"ç²å–å¯¦é©—æ¨¡å‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"ç²å–å¯¦é©—æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)}")


@router.post("/predict-only")
async def predict_only(request: PredictOnlyRequest):
    """ä½¿ç”¨å·²è¨“ç·´çš„æ¨¡å‹é€²è¡Œé æ¸¬"""
    try:
        from database import db_manager

        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        async with db_manager.session_factory() as session:
            from sqlalchemy import text
            q = text("SELECT model_path FROM trained_models WHERE id = :id AND status = 'COMPLETED'")
            r = await session.execute(q, {"id": request.model_id})
            row = r.first()
            if not row:
                raise HTTPException(status_code=404, detail="Trained model not found or not completed")
            model_path = row.model_path

        # é€²è¡Œé æ¸¬
        predictions = await training_service.predict_on_timerange(
            model_path,
            request.prediction_start_date,
            request.prediction_end_date,
            exclude_windows=None,
            time_range=request.time_range,
            floor_selection=request.floor_selection,
        )

        return {
            "success": True,
            "model_id": request.model_id,
            "predictions": predictions.get("predictions", []),
            "message": "Prediction completed successfully"
        }

    except Exception as e:
        logger.error(f"Prediction failed: {e}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

async def _train_model_background(
    task_id: str,
    model_name: str,
    model_type: str,
    model_params: Dict[str, Any]
):
    """èƒŒæ™¯ä»»å‹™ï¼šè¨“ç·´æ¨¡å‹"""
    try:
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        training_tasks[task_id]['status'] = 'running'
        training_tasks[task_id]['message'] = 'æ­£åœ¨æº–å‚™è¨“ç·´æ•¸æ“š...'
        training_tasks[task_id]['progress'] = 0.1

        # æª¢æŸ¥æ•¸æ“šæ˜¯å¦è¶³å¤ 
        training_tasks[task_id]['message'] = 'æ­£åœ¨æª¢æŸ¥æ•¸æ“šè³ªé‡...'
        training_tasks[task_id]['progress'] = 0.2

        # é€™è£¡å¯ä»¥æ·»åŠ æ•¸æ“šè³ªé‡æª¢æŸ¥é‚è¼¯

        training_tasks[task_id]['message'] = f'æ­£åœ¨è¨“ç·´ {model_type} æ¨¡å‹...'
        training_tasks[task_id]['progress'] = 0.4

        # åŸ·è¡Œå¯¦éš›çš„æ¨¡å‹è¨“ç·´
        model_id = await training_service.train_pu_model_in_background(
            model_name=model_name,
            model_type=model_type,
            model_params=model_params
        )

        training_tasks[task_id]['message'] = 'æ­£åœ¨è©•ä¼°æ¨¡å‹æ€§èƒ½...'
        training_tasks[task_id]['progress'] = 0.8

        # ç²å–è¨“ç·´çµæœ
        model_result = await training_service.get_latest_model_results()

        # ä»»å‹™å®Œæˆ
        training_tasks[task_id]['status'] = 'completed'
        training_tasks[task_id]['message'] = f'æ¨¡å‹ {model_name} è¨“ç·´å®Œæˆ'
        training_tasks[task_id]['progress'] = 1.0
        training_tasks[task_id]['result'] = {
            'model_id': model_id,
            'model_details': model_result,
            'completion_time': datetime.utcnow().isoformat(),
            'training_parameters': model_params
        }

        logger.info(f"æ¨¡å‹è¨“ç·´å®Œæˆ: {task_id}, æ¨¡å‹ID: {model_id}")

    except Exception as e:
        # ä»»å‹™å¤±æ•—
        error_msg = str(e)
        logger.error(f"æ¨¡å‹è¨“ç·´å¤±æ•—: {task_id}, éŒ¯èª¤: {error_msg}")

        training_tasks[task_id]['status'] = 'failed'
        training_tasks[task_id]['message'] = f'è¨“ç·´å¤±æ•—: {error_msg}'
        training_tasks[task_id]['error'] = error_msg
        training_tasks[task_id]['progress'] = 0.0

def _generate_performance_insights(model_result: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆæ¨¡å‹æ€§èƒ½æ´å¯Ÿ"""
    precision = model_result.get('precision', 0)
    recall = model_result.get('recall', 0)
    f1_score = model_result.get('f1Score', 0)

    insights = {
        'overall_performance': 'good' if f1_score > 0.7 else 'moderate' if f1_score > 0.5 else 'poor',
        'precision_level': 'high' if precision > 0.8 else 'medium' if precision > 0.6 else 'low',
        'recall_level': 'high' if recall > 0.8 else 'medium' if recall > 0.6 else 'low',
        'balance_analysis': {
            'is_balanced': abs(precision - recall) < 0.1,
            'bias_towards': 'precision' if precision > recall + 0.1 else 'recall' if recall > precision + 0.1 else 'balanced'
        }
    }

    return insights

def _generate_recommendations(model_result: Dict[str, Any]) -> List[str]:
    """ç”Ÿæˆæ”¹é€²å»ºè­°"""
    recommendations = []

    precision = model_result.get('precision', 0)
    recall = model_result.get('recall', 0)
    f1_score = model_result.get('f1Score', 0)

    if f1_score < 0.5:
        recommendations.append("æ¨¡å‹æ€§èƒ½è¼ƒä½ï¼Œå»ºè­°æ”¶é›†æ›´å¤šé«˜è³ªé‡çš„æ¨™è¨»æ•¸æ“š")

    if precision < 0.6:
        recommendations.append("ç²¾ç¢ºåº¦è¼ƒä½ï¼Œå¯èƒ½å­˜åœ¨éå¤šå‡é™½æ€§ï¼Œå»ºè­°èª¿æ•´æª¢æ¸¬é–¾å€¼")

    if recall < 0.6:
        recommendations.append("å¬å›ç‡è¼ƒä½ï¼Œå¯èƒ½éºæ¼çœŸå¯¦ç•°å¸¸ï¼Œå»ºè­°é™ä½æª¢æ¸¬é–¾å€¼æˆ–å¢åŠ ç•°å¸¸æ¨£æœ¬")

    if abs(precision - recall) > 0.2:
        recommendations.append("ç²¾ç¢ºåº¦å’Œå¬å›ç‡ä¸å¹³è¡¡ï¼Œå»ºè­°èª¿æ•´æ¨¡å‹åƒæ•¸æˆ–é‡æ–°å¹³è¡¡è¨“ç·´æ•¸æ“š")

    training_summary = model_result.get('trainingDataSummary', {})
    positive_samples = training_summary.get('positive_samples', 0)
    negative_samples = training_summary.get('reliable_negative_samples', 0)

    if positive_samples < 100:
        recommendations.append("æ­£æ¨£æœ¬æ•¸é‡è¼ƒå°‘ï¼Œå»ºè­°å¢åŠ æ›´å¤šç•°å¸¸äº‹ä»¶çš„æ¨™è¨»")

    if negative_samples < 100:
        recommendations.append("è² æ¨£æœ¬æ•¸é‡è¼ƒå°‘ï¼Œå»ºè­°æ¨™è¨»æ›´å¤šæ­£å¸¸äº‹ä»¶ä½œç‚ºå¯é è² æ¨£æœ¬")

    if not recommendations:
        recommendations.append("æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è€ƒæ…®åœ¨æ›´å¤§çš„æ•¸æ“šé›†ä¸Šé€²ä¸€æ­¥é©—è­‰")

    return recommendations

@router.delete("/tasks/{task_id}")
async def cleanup_training_task(task_id: str):
    """æ¸…ç†å·²å®Œæˆçš„è¨“ç·´ä»»å‹™"""
    if task_id in training_tasks:
        del training_tasks[task_id]
        return {"success": True, "message": "è¨“ç·´ä»»å‹™å·²æ¸…ç†"}
    else:
        raise HTTPException(status_code=404, detail="è¨“ç·´ä»»å‹™ä¸å­˜åœ¨")

@router.get("/tasks")
async def list_training_tasks():
    """åˆ—å‡ºæ‰€æœ‰è¨“ç·´ä»»å‹™ç‹€æ…‹"""
    return {
        "success": True,
        "tasks": {
            task_id: {
                'status': info['status'],
                'message': info['message'],
                'progress': info.get('progress', 0),
                'model_name': info.get('model_name'),
                'model_type': info.get('model_type'),
                'start_time': info['start_time'].isoformat()
            }
            for task_id, info in training_tasks.items()
        }
    }
