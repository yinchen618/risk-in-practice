"""
PU Learning é æ¸¬éšæ®µæ•¸æ“šæº–å‚™å‡½æ•¸
å¯¦ç¾èˆ‡è¨“ç·´éšæ®µå®Œå…¨ä¸€è‡´çš„æ•¸æ“šè™•ç†æµç¨‹
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging
from services.data_loader import DataLoaderService
from services.feature_engineering import feature_engineering

logger = logging.getLogger(__name__)

class PULearningPredictor:
    """PU Learning é æ¸¬å™¨ - è™•ç†é æ¸¬éšæ®µçš„æ•¸æ“šæº–å‚™"""

    def __init__(self):
        self.data_loader = DataLoaderService()

    async def prepare_prediction_data(
        self,
        time_range: Dict[str, str],
        building_floors: Dict[str, List[str]],
        sliding_window_minutes: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ç‚ºé æ¸¬æº–å‚™æ•¸æ“š - ä½¿ç”¨èˆ‡è¨“ç·´æ™‚å®Œå…¨ç›¸åŒçš„æµç¨‹

        Args:
            time_range: é æ¸¬æ™‚é–“ç¯„åœ {"start_date": "2025-08-14", "end_date": "2025-08-15", "start_time": "00:00", "end_time": "23:59"}
            building_floors: å»ºç¯‰æ¨“å±¤é¸æ“‡ {"Building A": ["2"], "Building B": ["1", "2"]}
            sliding_window_minutes: æ»‘å‹•çª—å£é–“éš”ï¼ˆåˆ†é˜ï¼‰

        Returns:
            List[Dict]: é æ¸¬æ¨£æœ¬åˆ—è¡¨ï¼Œæ¯å€‹åŒ…å« dataWindow
        """
        try:
            logger.info("ğŸ”®" + "="*50)
            logger.info("ğŸ”® PREPARING PREDICTION DATA")
            logger.info(f"ğŸ“… Time Range: {time_range}")
            logger.info(f"ğŸ¢ Building Floors: {building_floors}")
            logger.info(f"â±ï¸ Sliding Window: {sliding_window_minutes} minutes")
            logger.info("ğŸ”®" + "="*50)

            # 1. è§£ææ™‚é–“ç¯„åœ
            start_datetime = datetime.strptime(
                f"{time_range['start_date']} {time_range['start_time']}",
                "%Y-%m-%d %H:%M"
            )
            end_datetime = datetime.strptime(
                f"{time_range['end_date']} {time_range['end_time']}",
                "%Y-%m-%d %H:%M"
            )

            # 2. è¼‰å…¥åŸå§‹æ•¸æ“š
            start_time_str = start_datetime.isoformat()
            end_time_str = end_datetime.isoformat()

            raw_df = await self.data_loader.load_meter_data_by_time_range(
                start_time=start_time_str,
                end_time=end_time_str,
                selected_floors_by_building=building_floors
            )

            if raw_df.empty:
                logger.warning("âš ï¸ No raw data found for prediction")
                return []

            logger.info(f"ğŸ“Š Loaded {len(raw_df)} raw data records from {raw_df['deviceNumber'].nunique()} devices")

            # 3. ç”Ÿæˆæ»‘å‹•çª—å£é æ¸¬é»
            prediction_samples = await self._generate_sliding_window_samples(
                raw_df, start_datetime, end_datetime, sliding_window_minutes
            )

            logger.info("âœ…" + "="*50)
            logger.info(f"ğŸŠ PREDICTION DATA PREPARATION COMPLETED")
            logger.info(f"ğŸ“Š Generated {len(prediction_samples)} prediction samples")
            logger.info("âœ…" + "="*50)

            return prediction_samples

        except Exception as e:
            logger.error(f"ğŸ’¥ Failed to prepare prediction data: {e}")
            import traceback
            logger.error(f"ğŸ“ Traceback: {traceback.format_exc()}")
            return []

    async def _generate_sliding_window_samples(
        self,
        raw_df: pd.DataFrame,
        start_datetime: datetime,
        end_datetime: datetime,
        window_minutes: int
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨æ»‘å‹•çª—å£ç”Ÿæˆé æ¸¬æ¨£æœ¬"""
        try:
            # ç¢ºä¿æ™‚é–“æˆ³æ ¼å¼æ­£ç¢º
            if 'timestamp' not in raw_df.columns and 'lastUpdated' in raw_df.columns:
                raw_df = raw_df.rename(columns={'lastUpdated': 'timestamp'})

            raw_df['timestamp'] = pd.to_datetime(raw_df['timestamp'])
            raw_df = raw_df.sort_values(['deviceNumber', 'timestamp'])

            prediction_samples = []
            devices = raw_df['deviceNumber'].unique()

            # ç‚ºæ¯å€‹è¨­å‚™ç”Ÿæˆæ»‘å‹•çª—å£é æ¸¬é»
            for device_id in devices:
                device_df = raw_df[raw_df['deviceNumber'] == device_id].copy()

                # ç”Ÿæˆæ™‚é–“é»ï¼ˆæ¯ window_minutes åˆ†é˜ä¸€å€‹ï¼‰
                current_time = start_datetime
                sample_id = 0

                while current_time <= end_datetime:
                    # æª¢æŸ¥è©²æ™‚é–“é»é™„è¿‘æ˜¯å¦æœ‰æ•¸æ“š
                    nearby_data = device_df[
                        (device_df['timestamp'] >= current_time - timedelta(minutes=30)) &
                        (device_df['timestamp'] <= current_time + timedelta(minutes=30))
                    ]

                    if not nearby_data.empty:
                        # ç”Ÿæˆè©²æ™‚é–“é»çš„ dataWindow
                        data_window = await self._generate_prediction_data_window(
                            device_id, current_time, raw_df
                        )

                        if data_window and data_window.get('timeSeries'):
                            prediction_sample = {
                                "eventId": f"pred_{device_id}_{sample_id}",
                                "meterId": device_id,
                                "eventTimestamp": current_time.isoformat(),
                                "detectionRule": "prediction_sample",
                                "score": 0.0,
                                "dataWindow": data_window,
                                "status": "PREDICTION_SAMPLE"
                            }
                            prediction_samples.append(prediction_sample)
                            sample_id += 1

                    # ç§»å‹•åˆ°ä¸‹ä¸€å€‹æ™‚é–“é»
                    current_time += timedelta(minutes=window_minutes)

                logger.info(f"ğŸ“Š Generated {sample_id} prediction samples for device {device_id}")

            return prediction_samples

        except Exception as e:
            logger.error(f"Failed to generate sliding window samples: {e}")
            return []

    async def _generate_prediction_data_window(
        self,
        device_id: str,
        center_time: datetime,
        raw_df: pd.DataFrame
    ) -> Optional[Dict[str, Any]]:
        """ç‚ºé æ¸¬é»ç”Ÿæˆ dataWindow - èˆ‡è¨“ç·´æ™‚çš„é‚è¼¯å®Œå…¨ä¸€è‡´"""
        try:
            # ç¯©é¸è©²è¨­å‚™çš„æ•¸æ“š
            device_df = raw_df[raw_df['deviceNumber'] == device_id].copy()
            if device_df.empty:
                return None

            # ç¢ºä¿æ™‚é–“æˆ³æ ¼å¼
            time_col = 'timestamp'
            device_df[time_col] = pd.to_datetime(device_df[time_col])
            device_df = device_df.sort_values(time_col)

            # å®šç¾©æ™‚é–“çª—å£ï¼šä¸­å¿ƒæ™‚é–“å‰å¾Œå„ 15 åˆ†é˜
            window_start = center_time - timedelta(minutes=15)
            window_end = center_time + timedelta(minutes=15)

            # ç¯©é¸æ™‚é–“çª—å£å…§çš„æ•¸æ“š
            window_df = device_df[
                (device_df[time_col] >= window_start) &
                (device_df[time_col] <= window_end)
            ]

            if window_df.empty:
                return None

            # æ‰¾åˆ°æœ€æ¥è¿‘ä¸­å¿ƒæ™‚é–“çš„æ•¸æ“šé»
            time_diffs = abs(device_df[time_col] - center_time)
            if len(time_diffs) == 0:
                center_power_value = 0
            else:
                closest_idx = time_diffs.idxmin()
                center_power_value = device_df.loc[closest_idx, 'power'] if not device_df.empty else 0

            # æ§‹å»ºæ™‚åºæ•¸æ“šåˆ—è¡¨
            time_series = []
            for _, row in window_df.iterrows():
                time_series.append({
                    "timestamp": row[time_col].isoformat(),
                    "power": float(row['power']) if pd.notna(row['power']) else 0.0
                })

            # æ§‹å»º dataWindow å°è±¡ï¼ˆèˆ‡è¨“ç·´æ™‚æ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
            data_window = {
                "eventTimestamp": center_time.isoformat(),
                "eventPowerValue": float(center_power_value) if pd.notna(center_power_value) else 0.0,
                "windowStart": window_start.isoformat(),
                "windowEnd": window_end.isoformat(),
                "timeSeries": time_series,
                "totalDataPoints": len(time_series),
                "detectionRule": "prediction_sample",
                "anomalyScore": 0.0  # é æ¸¬æ™‚ä¸çŸ¥é“åˆ†æ•¸
            }

            return data_window

        except Exception as e:
            logger.error(f"Failed to generate prediction dataWindow: {e}")
            return None

    async def predict_with_model(
        self,
        model,
        prediction_samples: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œé æ¸¬"""
        try:
            logger.info(f"ğŸ”® Starting prediction on {len(prediction_samples)} samples")

            # 1. ç‰¹å¾µå·¥ç¨‹ - ä½¿ç”¨èˆ‡è¨“ç·´æ™‚å®Œå…¨ç›¸åŒçš„æµç¨‹
            feature_matrix, sample_ids = feature_engineering.generate_feature_matrix(prediction_samples)

            if feature_matrix.size == 0:
                logger.warning("âš ï¸ No features generated from prediction samples")
                return []

            # 2. æ¨™æº–åŒ–ç‰¹å¾µ - ä½¿ç”¨è¨“ç·´æ™‚çš„ scaler
            feature_matrix_scaled = feature_engineering.transform_features(feature_matrix)

            # è™•ç† NaN å€¼
            if np.isnan(feature_matrix_scaled).any():
                logger.warning("âš ï¸ Found NaN values in prediction features, filling with 0")
                feature_matrix_scaled = np.nan_to_num(feature_matrix_scaled, nan=0.0)

            # 3. æ¨¡å‹é æ¸¬
            if hasattr(model, 'predict_proba'):
                prediction_probs = model.predict_proba(feature_matrix_scaled)[:, 1]  # ç²å–ç•°å¸¸æ¦‚ç‡
                predictions = (prediction_probs > 0.5).astype(int)
            else:
                predictions = model.predict(feature_matrix_scaled)
                prediction_probs = predictions.astype(float)

            # 4. çµ„åˆé æ¸¬çµæœ
            prediction_results = []
            for i, (sample, prob, pred) in enumerate(zip(prediction_samples, prediction_probs, predictions)):
                result = {
                    "sampleId": sample["eventId"],
                    "meterId": sample["meterId"],
                    "timestamp": sample["eventTimestamp"],
                    "anomalyProbability": float(prob),
                    "isAnomalous": bool(pred),
                    "prediction": int(pred),
                    "deviceInfo": {
                        "deviceNumber": sample["meterId"]
                    }
                }
                prediction_results.append(result)

            logger.info(f"âœ… Prediction completed: {len(prediction_results)} results")
            logger.info(f"ğŸ“Š Anomalous samples: {sum(r['isAnomalous'] for r in prediction_results)}")

            return prediction_results

        except Exception as e:
            logger.error(f"ğŸ’¥ Prediction failed: {e}")
            import traceback
            logger.error(f"ğŸ“ Traceback: {traceback.format_exc()}")
            return []

# å‰µå»ºå…¨åŸŸå¯¦ä¾‹
pu_predictor = PULearningPredictor()
