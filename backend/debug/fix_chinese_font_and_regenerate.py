#!/usr/bin/env python3
"""
ä¿®å¾© matplotlib ä¸­æ–‡å­—é«”å•é¡Œä¸¦é‡æ–°ç”Ÿæˆç™¾è‘‰çª—æ•ˆæœåœ–ç‰‡
ä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•¸ã€é«˜æ–¯åˆ†å¸ƒã€æ›´å¤šç¥ç¶“å…ƒã€ç„¡æ­£è¦åŒ–çš„çµ„åˆ
é‡é»æ¸¬è©¦å¯èƒ½ç”¢ç”Ÿéæ“¬åˆçš„åƒæ•¸
"""

import requests
import json
import time
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import List, Dict
import os

def setup_chinese_font():
    """è¨­ç½®ä¸­æ–‡å­—é«”æ”¯æŒ"""
    print("ğŸ”§ è¨­ç½®ä¸­æ–‡å­—é«”æ”¯æŒ...")
    
    # å˜—è©¦è¨­ç½®ä¸­æ–‡å­—é«”
    chinese_fonts = [
        'SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 
        'DejaVu Sans', 'Arial Unicode MS', 'Noto Sans CJK SC'
    ]
    
    font_found = False
    for font_name in chinese_fonts:
        try:
            # æª¢æŸ¥å­—é«”æ˜¯å¦å­˜åœ¨
            font_path = fm.findfont(fm.FontProperties(family=font_name))
            if font_path != fm.rcParams['font.sans-serif'][0]:
                plt.rcParams['font.sans-serif'] = [font_name] + plt.rcParams['font.sans-serif']
                font_found = True
                print(f"âœ… æˆåŠŸè¨­ç½®ä¸­æ–‡å­—é«”: {font_name}")
                break
        except:
            continue
    
    if not font_found:
        # å¦‚æœæ‰¾ä¸åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨ç³»çµ±é»˜èªå­—é«”ä¸¦è¨­ç½® Unicode æ”¯æŒ
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans'] + plt.rcParams['font.sans-serif']
        print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨ Unicode æ”¯æŒ")
    
    # è¨­ç½® Unicode æ”¯æŒ
    plt.rcParams['axes.unicode_minus'] = False
    
    # æ¸¬è©¦ä¸­æ–‡å­—é«”
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'æ¸¬è©¦ä¸­æ–‡', fontsize=12)
        plt.close(fig)
        print("âœ… ä¸­æ–‡å­—é«”æ¸¬è©¦æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  ä¸­æ–‡å­—é«”æ¸¬è©¦å¤±æ•—: {e}")

def test_parameter_combination(params: Dict) -> Dict:
    """æ¸¬è©¦ç‰¹å®šåƒæ•¸çµ„åˆ"""
    
    url = "http://localhost:8000/api/pu-learning/run-simulation"
    
    payload = {
        "algorithm": "nnPU",
        "data_params": {
            "distribution": params["distribution"],
            "dims": params["dims"],
            "n_p": params["n_p"],
            "n_u": params["n_u"],
            "prior": params["prior"]
        },
        "model_params": {
            "activation": params["activation"],
            "n_epochs": params["n_epochs"],
            "learning_rate": params["learning_rate"],
            "hidden_dim": params["hidden_dim"],
            "weight_decay": params["weight_decay"]
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ API è«‹æ±‚å¤±æ•—: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ è«‹æ±‚ç•°å¸¸: {e}")
        return None

def analyze_decision_boundary(decision_boundary: List[List[float]]) -> Dict:
    """åˆ†ææ±ºç­–é‚Šç•Œçš„å¹³æ»‘åº¦"""
    
    if len(decision_boundary) < 3:
        return {"smoothness": 0, "oscillations": 0, "blinds_effect": False}
    
    # è½‰æ›ç‚º numpy é™£åˆ—
    boundary = np.array(decision_boundary)
    x_coords = boundary[:, 0]
    y_coords = boundary[:, 1]
    
    # è¨ˆç®—ç›¸é„°é»ä¹‹é–“çš„è®ŠåŒ–
    y_diffs = np.diff(y_coords)
    x_diffs = np.diff(x_coords)
    
    # è¨ˆç®—å¹³æ»‘åº¦æŒ‡æ¨™
    y_variance = np.var(y_diffs)
    y_mean_diff = np.mean(np.abs(y_diffs))
    
    # è¨ˆç®—æŒ¯ç›ªæ¬¡æ•¸ï¼ˆç¬¦è™Ÿè®ŠåŒ–æ¬¡æ•¸ï¼‰
    sign_changes = np.sum(np.diff(np.sign(y_diffs)) != 0)
    
    # è¨ˆç®—ç™¾è‘‰çª—æ•ˆæœæŒ‡æ¨™
    blinds_score = 0
    
    # æª¢æŸ¥æŒ¯ç›ªé »ç‡
    if sign_changes > len(y_diffs) * 0.3:  # è¶…é30%çš„é»æœ‰ç¬¦è™Ÿè®ŠåŒ–
        blinds_score += 1
    
    # æª¢æŸ¥å¤§å¹…è·³èº
    large_jumps = np.sum(np.abs(y_diffs) > np.std(y_coords) * 0.5)
    if large_jumps > len(y_diffs) * 0.2:  # è¶…é20%çš„é»æœ‰å¤§è·³èº
        blinds_score += 1
    
    # æª¢æŸ¥ Y åº§æ¨™è®ŠåŒ–ç¯„åœ
    y_range = np.max(y_coords) - np.min(y_coords)
    if y_range > 2.0:  # Y åº§æ¨™è®ŠåŒ–éå¤§
        blinds_score += 1
    
    # æª¢æŸ¥ç›¸é„°é»è·é›¢çš„ä¸€è‡´æ€§
    distances = np.sqrt(x_diffs**2 + y_diffs**2)
    distance_variance = np.var(distances)
    if distance_variance > np.mean(distances) * 0.5:  # è·é›¢è®ŠåŒ–éå¤§
        blinds_score += 1
    
    has_blinds_effect = blinds_score >= 2
    
    return {
        "smoothness": 1.0 / (1.0 + y_variance),  # å¹³æ»‘åº¦ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šå¹³æ»‘ï¼‰
        "oscillations": sign_changes,
        "y_variance": y_variance,
        "y_mean_diff": y_mean_diff,
        "y_range": y_range,
        "large_jumps": large_jumps,
        "distance_variance": distance_variance,
        "blinds_score": blinds_score,
        "blinds_effect": has_blinds_effect,
        "boundary_points": len(decision_boundary)
    }

def visualize_blinds_effect(result: Dict, config_name: str, analysis: Dict):
    """å¯è¦–åŒ–ç™¾è‘‰çª—æ•ˆæœ"""
    
    # æå–æ•¸æ“š
    p_samples = result['visualization']['p_samples']
    u_samples = result['visualization']['u_samples']
    decision_boundary = result['visualization']['decision_boundary']
    
    # å‰µå»ºåœ–è¡¨
    plt.figure(figsize=(15, 10))
    
    # ç¹ªè£½æ¨£æœ¬é»
    p_x, p_y = zip(*p_samples)
    u_x, u_y = zip(*u_samples)
    
    plt.scatter(p_x, p_y, c='red', s=50, alpha=0.7, label='æ­£æ¨£æœ¬ (P) / Positive Samples')
    plt.scatter(u_x, u_y, c='gray', s=30, alpha=0.5, label='æœªæ¨™è¨˜æ¨£æœ¬ (U) / Unlabeled Samples')
    
    # ç¹ªè£½æ±ºç­–é‚Šç•Œ
    boundary_x, boundary_y = zip(*decision_boundary)
    plt.plot(boundary_x, boundary_y, 'b-', linewidth=2, label='æ±ºç­–é‚Šç•Œ / Decision Boundary')
    
    # æ·»åŠ æ¨™é¡Œå’ŒæŒ‡æ¨™ï¼ˆä¸­è‹±æ–‡ä¸¦åˆ—ï¼‰
    title = f'nnPU ç™¾è‘‰çª—æ•ˆæœ / Blinds Effect: {config_name}\n'
    title += f'å¹³æ»‘åº¦ / Smoothness: {analysis["smoothness"]:.3f}, '
    title += f'æŒ¯ç›ªæ¬¡æ•¸ / Oscillations: {analysis["oscillations"]}, '
    title += f'ç™¾è‘‰çª—åˆ†æ•¸ / Blinds Score: {analysis["blinds_score"]}, '
    title += f'Yè®ŠåŒ–ç¯„åœ / Y Range: {analysis["y_range"]:.3f}'
    
    plt.title(title, fontsize=14, fontweight='bold')
    plt.xlabel('X åº§æ¨™ / X Coordinate', fontsize=12)
    plt.ylabel('Y åº§æ¨™ / Y Coordinate', fontsize=12)
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    # ä¿å­˜åœ–ç‰‡
    filename = f'nnpu_gaussian_overfitting_{config_name.replace(" ", "_").replace("=", "_")}.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"âœ… å¯è¦–åŒ–åœ–ç‰‡å·²ä¿å­˜: {filename}")

def test_gaussian_overfitting_configurations():
    """æ¸¬è©¦ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„éæ“¬åˆåƒæ•¸é…ç½®"""
    
    print("ğŸ” æ¸¬è©¦ nnPU é«˜æ–¯åˆ†å¸ƒéæ“¬åˆåƒæ•¸çµ„åˆ...")
    print("=" * 80)
    
    # å®šç¾©ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„éæ“¬åˆåƒæ•¸çµ„åˆ
    # é‡é»ï¼šé«˜æ–¯åˆ†å¸ƒ + å¯èƒ½å°è‡´éæ“¬åˆçš„åƒæ•¸
    gaussian_configs = [
        {
            "name": "Gaussian_æ¥µé«˜å­¸ç¿’ç‡_å¤šç¥ç¶“å…ƒ_ç„¡æ­£è¦åŒ–",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.3,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.5,
                "hidden_dim": 200,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_æ¥µé«˜å­¸ç¿’ç‡_æ›´å¤šç¥ç¶“å…ƒ_ç„¡æ­£è¦åŒ–",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.3,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.8,
                "hidden_dim": 300,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_é«˜å­¸ç¿’ç‡_æ¥µå¤šç¥ç¶“å…ƒ_ç„¡æ­£è¦åŒ–",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.3,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.3,
                "hidden_dim": 500,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_æ¥µé«˜å­¸ç¿’ç‡_å¤šç¥ç¶“å…ƒ_ä½å…ˆé©—",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.2,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.6,
                "hidden_dim": 200,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_é«˜å­¸ç¿’ç‡_å¤šç¥ç¶“å…ƒ_é«˜å…ˆé©—",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.4,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.4,
                "hidden_dim": 200,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_æ¥µé«˜å­¸ç¿’ç‡_æ›´å¤šç¥ç¶“å…ƒ_ä¸å¹³è¡¡æ•¸æ“š",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 30,
                "n_u": 400,
                "prior": 0.3,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.7,
                "hidden_dim": 300,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_é«˜å­¸ç¿’ç‡_æ¥µå¤šç¥ç¶“å…ƒ_æ¥µä¸å¹³è¡¡æ•¸æ“š",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 20,
                "n_u": 500,
                "prior": 0.3,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.3,
                "hidden_dim": 500,
                "weight_decay": 0.0
            }
        },
        {
            "name": "Gaussian_æ¥µé«˜å­¸ç¿’ç‡_å¤šç¥ç¶“å…ƒ_æ¥µä½å…ˆé©—",
            "params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.1,
                "activation": "relu",
                "n_epochs": 100,
                "learning_rate": 0.9,
                "hidden_dim": 200,
                "weight_decay": 0.0
            }
        }
    ]
    
    results = []
    
    for i, config in enumerate(gaussian_configs):
        print(f"\nğŸ”§ æ¸¬è©¦é…ç½® {i+1}/{len(gaussian_configs)}: {config['name']}")
        print(f"   åƒæ•¸: {config['params']}")
        
        # æ¸¬è©¦åƒæ•¸çµ„åˆ
        result = test_parameter_combination(config['params'])
        
        if result and result.get('success'):
            print("âœ… æ¨¡æ“¬æˆåŠŸ")
            
            # åˆ†ææ±ºç­–é‚Šç•Œ
            decision_boundary = result['visualization']['decision_boundary']
            analysis = analyze_decision_boundary(decision_boundary)
            
            print(f"   åˆ†æçµæœ:")
            print(f"   - å¹³æ»‘åº¦: {analysis['smoothness']:.3f}")
            print(f"   - æŒ¯ç›ªæ¬¡æ•¸: {analysis['oscillations']}")
            print(f"   - ç™¾è‘‰çª—åˆ†æ•¸: {analysis['blinds_score']}")
            print(f"   - æœ‰ç™¾è‘‰çª—æ•ˆæœ: {analysis['blinds_effect']}")
            
            # ç”Ÿæˆå¯è¦–åŒ–
            visualize_blinds_effect(result, config['name'], analysis)
            
            # ä¿å­˜çµæœ
            results.append({
                "config": config,
                "analysis": analysis,
                "metrics": result['metrics']
            })
            
            # è½‰æ› numpy é¡å‹ç‚º Python åŸç”Ÿé¡å‹
            for key in analysis:
                if isinstance(analysis[key], np.integer):
                    analysis[key] = int(analysis[key])
                elif isinstance(analysis[key], np.floating):
                    analysis[key] = float(analysis[key])
                elif isinstance(analysis[key], np.bool_):
                    analysis[key] = bool(analysis[key])
            
        else:
            print("âŒ æ¨¡æ“¬å¤±æ•—")
        
        # ç­‰å¾…ä¸€ä¸‹é¿å…è«‹æ±‚éæ–¼é »ç¹
        time.sleep(1)
    
    # ä¿å­˜çµæœåˆ° JSON æ–‡ä»¶
    results_data = []
    for result in results:
        result_data = {
            "config_name": result["config"]["name"],
            "params": result["config"]["params"],
            "analysis": result["analysis"],
            "metrics": result["metrics"]
        }
        results_data.append(result_data)
    
    with open('gaussian_overfitting_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š æ¸¬è©¦å®Œæˆï¼å…±æ¸¬è©¦ {len(gaussian_configs)} å€‹é…ç½®")
    print(f"âœ… æˆåŠŸ: {len(results)} å€‹")
    print(f"âŒ å¤±æ•—: {len(gaussian_configs) - len(results)} å€‹")
    
    # é¡¯ç¤ºæœ‰ç™¾è‘‰çª—æ•ˆæœçš„é…ç½®
    blinds_effects = [r for r in results if r['analysis']['blinds_effect']]
    if blinds_effects:
        print(f"\nğŸ¯ ç™¼ç¾ {len(blinds_effects)} å€‹æœ‰ç™¾è‘‰çª—æ•ˆæœçš„é…ç½®:")
        for effect in blinds_effects:
            print(f"   - {effect['config']['name']}")
            print(f"     ç™¾è‘‰çª—åˆ†æ•¸: {effect['analysis']['blinds_score']}")
            print(f"     æŒ¯ç›ªæ¬¡æ•¸: {effect['analysis']['oscillations']}")
    else:
        print("\nâš ï¸  æœªç™¼ç¾æ˜é¡¯çš„ç™¾è‘‰çª—æ•ˆæœ")
    
    return results

if __name__ == "__main__":
    # è¨­ç½®ä¸­æ–‡å­—é«”
    setup_chinese_font()
    
    # æ¸¬è©¦é«˜æ–¯åˆ†å¸ƒçš„éæ“¬åˆåƒæ•¸
    test_gaussian_overfitting_configurations() 
