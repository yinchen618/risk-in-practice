#!/usr/bin/env python3
"""
å…ˆé©—ä¼°è¨ˆå‡½æ•¸èª¿è©¦èˆ‡ä¿®æ­£
é©—è­‰ estimate_prior_penL1CP å‡½æ•¸æ˜¯å¦å­˜åœ¨å•é¡Œ
"""

import numpy as np
import sys
import os

# æ·»åŠ å¾Œç«¯è·¯å¾‘
backend_dir = os.path.dirname(os.path.abspath(__file__))
pu_learning_dir = os.path.join(backend_dir, 'pu-learning')
if pu_learning_dir not in sys.path:
    sys.path.append(pu_learning_dir)

from data_generator import generate_synthetic_data

def debug_prior_estimation():
    """èª¿è©¦ç¾æœ‰çš„å…ˆé©—ä¼°è¨ˆå‡½æ•¸"""
    print("ğŸ” èª¿è©¦å…ˆé©—ä¼°è¨ˆå‡½æ•¸")
    print("="*60)
    
    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    xp, xu, xt_p, xt_n = generate_synthetic_data(
        distribution='two_moons',
        dims=2,
        n_p=50,
        n_u=300,
        prior=0.3,
        n_test=1000
    )
    
    print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“š:")
    print(f"   â€¢ æ­£æ¨£æœ¬: {len(xp)}")
    print(f"   â€¢ æœªæ¨™è¨˜æ¨£æœ¬: {len(xu)}")
    print(f"   â€¢ çœŸå¯¦å…ˆé©—: 0.3")
    
    # æ‰‹å‹•å¯¦ç¾ç¾æœ‰é‚è¼¯
    from sklearn.neighbors import KernelDensity
    
    print(f"\nğŸ” åˆ†æç¾æœ‰å…ˆé©—ä¼°è¨ˆé‚è¼¯:")
    
    try:
        # æ ¸å¯†åº¦ä¼°è¨ˆ
        kde_p = KernelDensity(bandwidth=0.5, kernel='gaussian')
        kde_u = KernelDensity(bandwidth=0.5, kernel='gaussian')
        
        kde_p.fit(xp)
        kde_u.fit(xu)
        
        # åœ¨æœªæ¨™è¨˜æ¨£æœ¬ä¸Šè©•ä¼°å¯†åº¦
        log_dens_p = kde_p.score_samples(xu)
        log_dens_u = kde_u.score_samples(xu)
        
        # è¨ˆç®—å¯†åº¦æ¯”
        density_ratio = np.exp(log_dens_p - log_dens_u)
        
        print(f"   â€¢ å¯†åº¦æ¯”çµ±è¨ˆ:")
        print(f"      - æœ€å°å€¼: {np.min(density_ratio):.4f}")
        print(f"      - æœ€å¤§å€¼: {np.max(density_ratio):.4f}")
        print(f"      - å‡å€¼: {np.mean(density_ratio):.4f}")
        print(f"      - ä¸­ä½æ•¸: {np.median(density_ratio):.4f}")
        print(f"      - æ¨™æº–å·®: {np.std(density_ratio):.4f}")
        
        # ç¾æœ‰ä¼°è¨ˆæ–¹æ³•
        estimated_prior_old = np.clip(np.mean(density_ratio), 0.1, 0.9)
        print(f"   â€¢ ç¾æœ‰æ–¹æ³•çµæœ: {estimated_prior_old:.4f}")
        
        # å•é¡Œåˆ†æ
        if np.mean(density_ratio) > 0.9:
            print(f"   âŒ å•é¡Œï¼šå¯†åº¦æ¯”å‡å€¼ ({np.mean(density_ratio):.4f}) è¶…é 0.9ï¼Œè¢«è£å‰ªï¼")
        
        # å˜—è©¦æ”¹é€²æ–¹æ³•
        print(f"\nğŸ’¡ å˜—è©¦æ”¹é€²çš„å…ˆé©—ä¼°è¨ˆæ–¹æ³•:")
        
        # æ–¹æ³•1ï¼šä½¿ç”¨ä¸­ä½æ•¸è€Œä¸æ˜¯å‡å€¼
        estimated_prior_v1 = np.clip(np.median(density_ratio), 0.1, 0.9)
        print(f"   â€¢ æ–¹æ³•1 (ä¸­ä½æ•¸): {estimated_prior_v1:.4f}")
        
        # æ–¹æ³•2ï¼šä½¿ç”¨å°æ•¸ç©ºé–“å¹³å‡
        log_ratio = log_dens_p - log_dens_u
        estimated_prior_v2 = np.clip(np.exp(np.mean(log_ratio)), 0.1, 0.9)
        print(f"   â€¢ æ–¹æ³•2 (å°æ•¸å¹³å‡): {estimated_prior_v2:.4f}")
        
        # æ–¹æ³•3ï¼šåŸºæ–¼åˆ†ä½æ•¸çš„ä¼°è¨ˆ
        percentile_75 = np.percentile(density_ratio, 75)
        estimated_prior_v3 = np.clip(percentile_75, 0.1, 0.9)
        print(f"   â€¢ æ–¹æ³•3 (75%åˆ†ä½æ•¸): {estimated_prior_v3:.4f}")
        
        # æ–¹æ³•4ï¼šåŸºæ–¼å¯¦éš›å¯†åº¦ä¼°è¨ˆçš„æ”¹é€²æ–¹æ³•
        # ä½¿ç”¨è²è‘‰æ–¯å®šç†ï¼šP(y=1|x) = P(x|y=1) * P(y=1) / P(x)
        # å…¶ä¸­ P(x) = P(x|y=1) * P(y=1) + P(x|y=0) * P(y=0)
        
        # è¨ˆç®—åœ¨æ‰€æœ‰æœªæ¨™è¨˜æ¨£æœ¬ä¸Šçš„å¯†åº¦
        p_density = np.exp(log_dens_p)  # P(x|y=1)
        u_density = np.exp(log_dens_u)  # è¿‘ä¼¼ P(x)
        
        # å‡è¨­å…ˆé©—ï¼Œç„¶å¾Œè¿­ä»£ä¼°è¨ˆ
        prior_guess = 0.3
        for iteration in range(10):
            # è¨ˆç®—å¾Œé©—æ¦‚ç‡
            posterior = (p_density * prior_guess) / u_density
            posterior = np.clip(posterior, 0.01, 0.99)
            
            # æ›´æ–°å…ˆé©—ä¼°è¨ˆ
            new_prior = np.mean(posterior)
            
            if abs(new_prior - prior_guess) < 0.001:
                break
            prior_guess = new_prior
        
        estimated_prior_v4 = np.clip(prior_guess, 0.1, 0.9)
        print(f"   â€¢ æ–¹æ³•4 (è¿­ä»£è²è‘‰æ–¯): {estimated_prior_v4:.4f} (æ”¶æ–‚æ–¼ {iteration+1} æ¬¡è¿­ä»£)")
        
        # æ–¹æ³•5ï¼šç°¡å–®çš„åŸºæ–¼æ¨£æœ¬æ¯”ä¾‹çš„ä¼°è¨ˆ
        # å‡è¨­æ­£æ¨£æœ¬åœ¨æœªæ¨™è¨˜æ¨£æœ¬ä¸­çš„æ¯”ä¾‹
        # é€šéæ¯”è¼ƒæ­£æ¨£æœ¬èˆ‡æœªæ¨™è¨˜æ¨£æœ¬çš„å¯†åº¦ä¾†ä¼°è¨ˆ
        
        # è¨ˆç®—æ­£æ¨£æœ¬åœ¨å…¶è‡ªèº«åˆ†å¸ƒä¸‹çš„å¹³å‡å¯†åº¦
        p_self_density = np.mean(np.exp(kde_p.score_samples(xp)))
        # è¨ˆç®—æ­£æ¨£æœ¬åœ¨æœªæ¨™è¨˜åˆ†å¸ƒä¸‹çš„å¹³å‡å¯†åº¦
        p_in_u_density = np.mean(np.exp(kde_u.score_samples(xp)))
        
        # ç°¡å–®æ¯”ä¾‹ä¼°è¨ˆ
        if p_in_u_density > 0:
            ratio_estimate = p_in_u_density / p_self_density
            estimated_prior_v5 = np.clip(ratio_estimate, 0.1, 0.9)
            print(f"   â€¢ æ–¹æ³•5 (å¯†åº¦æ¯”ä¾‹): {estimated_prior_v5:.4f}")
        else:
            estimated_prior_v5 = 0.3
            print(f"   â€¢ æ–¹æ³•5 (å¯†åº¦æ¯”ä¾‹): {estimated_prior_v5:.4f} (é»˜èªå€¼)")
        
        # æ¯”è¼ƒçµæœ
        true_prior = 0.3
        methods = [
            ('ç¾æœ‰æ–¹æ³•', estimated_prior_old),
            ('ä¸­ä½æ•¸æ³•', estimated_prior_v1),
            ('å°æ•¸å¹³å‡', estimated_prior_v2),
            ('75%åˆ†ä½æ•¸', estimated_prior_v3),
            ('è¿­ä»£è²è‘‰æ–¯', estimated_prior_v4),
            ('å¯†åº¦æ¯”ä¾‹', estimated_prior_v5)
        ]
        
        print(f"\nğŸ“Š æ–¹æ³•æ¯”è¼ƒ (çœŸå¯¦å…ˆé©—: {true_prior}):")
        print(f"{'æ–¹æ³•':>12} {'ä¼°è¨ˆå€¼':>8} {'èª¤å·®':>8}")
        print(f"{'-'*30}")
        
        best_method = None
        best_error = float('inf')
        
        for method_name, estimate in methods:
            error = abs(estimate - true_prior)
            print(f"{method_name:>12} {estimate:>8.4f} {error:>8.4f}")
            
            if error < best_error:
                best_error = error
                best_method = (method_name, estimate)
        
        if best_method:
            print(f"\nğŸ† æœ€ä½³æ–¹æ³•: {best_method[0]} (èª¤å·®: {best_error:.4f})")
            
            if best_error < 0.1:
                print(f"âœ… æ‰¾åˆ°äº†æœ‰æ•ˆçš„å…ˆé©—ä¼°è¨ˆæ–¹æ³•ï¼")
                return best_method
            else:
                print(f"âš ï¸  æ”¹å–„æœ‰é™ï¼Œä½†æ¯”ç¾æœ‰æ–¹æ³•æ›´å¥½")
                return best_method
        
    except Exception as e:
        print(f"âŒ èª¿è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_different_priors_with_debug():
    """ä½¿ç”¨èª¿è©¦ä¿¡æ¯æ¸¬è©¦ä¸åŒå…ˆé©—"""
    print(f"\nğŸ§ª æ¸¬è©¦ä¸åŒå…ˆé©—ä¸‹çš„å¯†åº¦æ¯”è¡Œç‚º")
    print("="*60)
    
    from sklearn.neighbors import KernelDensity
    
    priors_to_test = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]
    
    for prior in priors_to_test:
        xp, xu, xt_p, xt_n = generate_synthetic_data(
            distribution='two_moons',
            dims=2,
            n_p=50,
            n_u=300,
            prior=prior,
            n_test=1000
        )
        
        kde_p = KernelDensity(bandwidth=0.5, kernel='gaussian')
        kde_u = KernelDensity(bandwidth=0.5, kernel='gaussian')
        
        kde_p.fit(xp)
        kde_u.fit(xu)
        
        log_dens_p = kde_p.score_samples(xu)
        log_dens_u = kde_u.score_samples(xu)
        density_ratio = np.exp(log_dens_p - log_dens_u)
        
        mean_ratio = np.mean(density_ratio)
        clipped_ratio = np.clip(mean_ratio, 0.1, 0.9)
        
        print(f"å…ˆé©— {prior:.1f}: å¯†åº¦æ¯”å‡å€¼ {mean_ratio:.4f} â†’ è£å‰ªå¾Œ {clipped_ratio:.4f}")

if __name__ == "__main__":
    # é‹è¡Œèª¿è©¦
    best_method = debug_prior_estimation()
    
    # æ¸¬è©¦ä¸åŒå…ˆé©—
    test_different_priors_with_debug()
    
    if best_method:
        print(f"\nğŸ’¡ å»ºè­°:")
        print(f"   â€¢ å°‡ç¾æœ‰çš„å…ˆé©—ä¼°è¨ˆæ–¹æ³•æ›¿æ›ç‚º: {best_method[0]}")
        print(f"   â€¢ é€™å°‡å¤§å¹…æ”¹å–„å…ˆé©—ä¼°è¨ˆçš„æº–ç¢ºæ€§")
        print(f"   â€¢ ä¿®æ­£å¾Œå¯èƒ½è§£æ±º nnPU çš„éæ“¬åˆå•é¡Œ")
