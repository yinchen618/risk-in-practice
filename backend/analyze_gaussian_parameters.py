#!/usr/bin/env p            self.base_config = {
            "algorithm": "nnPU",
            "data_params": {
                "distribution": "gaussian",
                "dims": 8,         # ä½¿ç”¨8ç¶­ï¼ˆæœ€ä½³å¹³è¡¡é»ï¼‰
                "n_p": 50,
                "n_u": 300,
                "prior": 0.3,
                "noise_level": 0.8,  # æ–°å¢å™ªéŸ³æ§åˆ¶
                "center_dist": 2.0   # æ–°å¢ä¸­å¿ƒè·é›¢æ§åˆ¶
            },
            "model_params": {
                "activation": "relu",
                "n_epochs": 30,      # 30è¼ªè¶³å¤ 
                "learning_rate": 0.01, # è¼ƒå¤§å­¸ç¿’ç‡æ•ˆæœæ›´å¥½
                "hidden_dim": 200,    # å¤§æ¨¡å‹æ•ˆæœå¥½
                "weight_decay": 0.0001 # è¼•å¾®æ­£å‰‡åŒ–
            }æ•¸è©³ç´°åˆ†æ
æ¸¬è©¦å„ç¨®åƒæ•¸çµ„åˆä¸¦åˆ†æå…¶åˆç†æ€§
"""
import requests
import numpy as np
import json
from typing import Dict, List, Tuple
import time
from tabulate import tabulate
from collections import defaultdict

class ParameterAnalyzer:
    def __init__(self):
        self.url = "http://localhost:8000/api/pu-learning/run-simulation"
        self.base_config = {
            "algorithm": "nnPU",
            "data_params": {
                "distribution": "gaussian",
                "dims": 2,
                "n_p": 50,
                "n_u": 300,
                "prior": 0.3
            },
            "model_params": {
                "activation": "relu",
                "n_epochs": 50,
                "learning_rate": 0.001,
                "hidden_dim": 200,
                "weight_decay": 0.005
            }
        }
        
    def run_experiment(self, **kwargs) -> Dict:
        """é‹è¡Œå–®æ¬¡å¯¦é©—"""
        config = self.base_config.copy()
        for k, v in kwargs.items():
            if k.startswith('data_'):
                config['data_params'][k[5:]] = v
            elif k.startswith('model_'):
                config['model_params'][k[6:]] = v
        
        try:
            response = requests.post(self.url, json=config, timeout=30)
            if response.status_code == 200:
                data = response.json()
                return {
                    'error_rate': data['metrics']['error_rate'],
                    'estimated_prior': data['metrics']['estimated_prior'],
                    'prior_error': abs(data['metrics']['estimated_prior'] - config['data_params']['prior'])
                }
            else:
                return None
        except Exception as e:
            print(f"å¯¦é©—å¤±æ•—: {e}")
            return None
    
    def analyze_parameter(self, param_name: str, values: List, n_repeats: int = 3) -> Dict:
        """åˆ†æå–®å€‹åƒæ•¸çš„å½±éŸ¿"""
        results = defaultdict(list)
        
        print(f"\nğŸ” åˆ†æåƒæ•¸: {param_name}")
        print("="*60)
        
        for value in values:
            print(f"æ¸¬è©¦ {param_name} = {value}")
            for i in range(n_repeats):
                result = self.run_experiment(**{param_name: value})
                if result:
                    results[value].append(result)
                time.sleep(0.1)  # é¿å…è«‹æ±‚éå¿«
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        stats = {}
        for value in values:
            if results[value]:
                error_rates = [r['error_rate'] for r in results[value]]
                prior_errors = [r['prior_error'] for r in results[value]]
                
                stats[value] = {
                    'mean_error': np.mean(error_rates),
                    'std_error': np.std(error_rates),
                    'mean_prior_error': np.mean(prior_errors),
                    'std_prior_error': np.std(prior_errors)
                }
        
        return stats
    
    def analyze_all_parameters(self):
        """åˆ†ææ‰€æœ‰é‡è¦åƒæ•¸"""
        parameters = {
            'model_hidden_dim': [32, 64, 128, 200, 256],
            'model_weight_decay': [0, 0.0001, 0.001, 0.005, 0.01],
            'data_dims': [2, 4, 8, 16],
            'model_n_epochs': [30, 50, 100],
            'model_learning_rate': [0.0001, 0.001, 0.01]
        }
        
        all_results = {}
        for param_name, values in parameters.items():
            all_results[param_name] = self.analyze_parameter(param_name, values)
            self.print_parameter_analysis(param_name, all_results[param_name])
        
        return all_results
    
    def print_parameter_analysis(self, param_name: str, stats: Dict):
        """æ‰“å°åƒæ•¸åˆ†æçµæœ"""
        print(f"\nğŸ“Š {param_name} åˆ†æçµæœ:")
        print("="*60)
        
        headers = ["å€¼", "éŒ¯èª¤ç‡ (mean Â± std)", "å…ˆé©—èª¤å·® (mean Â± std)"]
        rows = []
        
        for value, stat in stats.items():
            rows.append([
                value,
                f"{stat['mean_error']*100:.1f}% Â± {stat['std_error']*100:.1f}%",
                f"{stat['mean_prior_error']:.3f} Â± {stat['std_prior_error']:.3f}"
            ])
        
        print(tabulate(rows, headers=headers, tablefmt="grid"))
        
        # æ‰¾å‡ºæœ€ä½³å€¼
        best_error = min(stats.items(), key=lambda x: x[1]['mean_error'])
        best_prior = min(stats.items(), key=lambda x: x[1]['mean_prior_error'])
        
        print(f"\nğŸ† æœ€ä½³å€¼:")
        print(f"   â€¢ éŒ¯èª¤ç‡æœ€ä½: {best_error[0]} ({best_error[1]['mean_error']*100:.1f}%)")
        print(f"   â€¢ å…ˆé©—ä¼°è¨ˆæœ€æº–: {best_prior[0]} ({best_prior[1]['mean_prior_error']:.3f})")
        
        # ç©©å®šæ€§åˆ†æ
        stability = {v: s['std_error'] for v, s in stats.items()}
        most_stable = min(stability.items(), key=lambda x: x[1])
        print(f"   â€¢ æœ€ç©©å®šå€¼: {most_stable[0]} (std={most_stable[1]*100:.1f}%)")

def main():
    print("ğŸ§ª é–‹å§‹é«˜æ–¯åˆ†å¸ƒè©³ç´°åƒæ•¸åˆ†æ")
    print("="*80)
    print("ç›®æ¨™: æ‰¾å‡ºæœ€å„ªä¸”ç©©å®šçš„åƒæ•¸çµ„åˆ")
    
    analyzer = ParameterAnalyzer()
    results = analyzer.analyze_all_parameters()
    
    # ç¸½çµ
    print("\nğŸ“‹ åˆ†æç¸½çµ")
    print("="*80)
    
    # è¨ˆç®—æ¯å€‹åƒæ•¸çš„ç¶œåˆå¾—åˆ† (è€ƒæ…®éŒ¯èª¤ç‡ã€å…ˆé©—æº–ç¢ºåº¦å’Œç©©å®šæ€§)
    best_params = {}
    for param_name, stats in results.items():
        scores = {}
        for value, stat in stats.items():
            # ç¶œåˆå¾—åˆ† = 0.6 * éŒ¯èª¤ç‡ + 0.3 * å…ˆé©—èª¤å·® + 0.1 * ç©©å®šæ€§
            score = (0.6 * stat['mean_error'] + 
                    0.3 * stat['mean_prior_error'] + 
                    0.1 * stat['std_error'])
            scores[value] = score
        
        best_value = min(scores.items(), key=lambda x: x[1])[0]
        best_params[param_name] = best_value
    
    print("æ¨è–¦é…ç½®:")
    for param, value in best_params.items():
        print(f"   â€¢ {param}: {value}")
    
    # é©—è­‰æœ€ä½³çµ„åˆ
    print("\nğŸ” é©—è­‰æœ€ä½³çµ„åˆ")
    print("="*60)
    
    analyzer = ParameterAnalyzer()
    final_results = []
    for _ in range(5):
        result = analyzer.run_experiment(**best_params)
        if result:
            final_results.append(result)
    
    if final_results:
        mean_error = np.mean([r['error_rate'] for r in final_results])
        std_error = np.std([r['error_rate'] for r in final_results])
        mean_prior = np.mean([r['prior_error'] for r in final_results])
        std_prior = np.std([r['prior_error'] for r in final_results])
        
        print(f"æœ€çµ‚æ€§èƒ½ (5æ¬¡æ¸¬è©¦å¹³å‡):")
        print(f"   â€¢ éŒ¯èª¤ç‡: {mean_error*100:.1f}% Â± {std_error*100:.1f}%")
        print(f"   â€¢ å…ˆé©—èª¤å·®: {mean_prior:.3f} Â± {std_prior:.3f}")
        
        if mean_error < 0.1 and std_error < 0.02:
            print("âœ… æ‰¾åˆ°ç©©å®šä¸”è‰¯å¥½çš„é…ç½®!")
        else:
            print("âš ï¸  é…ç½®æ€§èƒ½æˆ–ç©©å®šæ€§æœ‰å¾…æ”¹é€²")

if __name__ == "__main__":
    main()
