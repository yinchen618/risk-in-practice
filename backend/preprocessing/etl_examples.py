"""
æ•¸æ“šé è™•ç† ETL ä½¿ç”¨ç¯„ä¾‹

é€™å€‹è…³æœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ data_preprocessing_etl.py ä¾†è™•ç†é›»éŒ¶æ•¸æ“šã€‚
åŒ…å«å–®å€‹æˆ¿é–“è™•ç†å’Œæ‰¹é‡è™•ç†çš„ç¯„ä¾‹ã€‚

åŸ·è¡Œå‰è«‹ç¢ºä¿ï¼š
1. è³‡æ–™åº«é€£æ¥æ­£å¸¸
2. å·²åŸ·è¡Œ Prisma é·ç§»ä»¥å‰µå»ºæ–°çš„è³‡æ–™è¡¨
3. åŸå§‹é›»éŒ¶æ•¸æ“šå·²å­˜åœ¨æ–¼ ammeter è¡¨ä¸­
"""

import asyncio
import os
from datetime import datetime
from typing import List

from data_preprocessing_etl import DataPreprocessingETL, RoomInfo, OccupantType
from etl_config import PREDEFINED_ROOMS, TIME_RANGES, ETL_CONFIG

async def example_single_room_processing():
    """
    ç¯„ä¾‹ï¼šè™•ç†å–®å€‹æˆ¿é–“çš„æ•¸æ“š
    """
    print("=== å–®å€‹æˆ¿é–“è™•ç†ç¯„ä¾‹ ===")

    # å¾ç’°å¢ƒè®Šæ•¸æˆ–ä½¿ç”¨é è¨­å€¼ç²å–æ•¸æ“šåº« URL
    database_url = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/pu_practice")

    # å‰µå»º ETL è™•ç†å™¨
    etl = DataPreprocessingETL(database_url)

    try:
        # é€£æ¥æ•¸æ“šåº«
        await etl.connect_database()

        # å®šç¾©è¦è™•ç†çš„æˆ¿é–“ (å¯ä»¥ä¿®æ”¹ç‚ºæ‚¨çš„å¯¦éš›æˆ¿é–“è³‡è¨Š)
        room_info = RoomInfo(
            building="Building-A",
            floor="3F",
            room="Room-301",
            meter_id_l1="actual_meter_l1_id",  # è«‹æ›¿æ›ç‚ºçœŸå¯¦çš„é›»éŒ¶ ID
            meter_id_l2="actual_meter_l2_id",  # è«‹æ›¿æ›ç‚ºçœŸå¯¦çš„é›»éŒ¶ ID
            occupant_type=OccupantType.OFFICE_WORKER
        )

        # å®šç¾©è™•ç†æ™‚é–“ç¯„åœ (2025å¹´8æœˆ)
        search_start = datetime(2025, 8, 1)
        search_end = datetime(2025, 8, 31)

        print(f"é–‹å§‹è™•ç†æˆ¿é–“: {room_info.building}-{room_info.floor}-{room_info.room}")
        print(f"æœç´¢ç¯„åœ: {search_start} åˆ° {search_end}")

        # åŸ·è¡Œ ETL æµç¨‹
        dataset_id = await etl.process_room_data(
            room_info=room_info,
            search_start=search_start,
            search_end=search_end,
            window_days=7
        )

        print(f"âœ… è™•ç†å®Œæˆï¼å‰µå»ºçš„æ•¸æ“šé›† ID: {dataset_id}")

    except Exception as e:
        print(f"âŒ è™•ç†å¤±æ•—: {e}")

    finally:
        await etl.close_database()

async def example_batch_processing():
    """
    ç¯„ä¾‹ï¼šæ‰¹é‡è™•ç†å¤šå€‹æˆ¿é–“
    """
    print("\n=== æ‰¹é‡è™•ç†ç¯„ä¾‹ ===")

    database_url = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/pu_practice")
    etl = DataPreprocessingETL(database_url)

    try:
        await etl.connect_database()

        # ä½¿ç”¨é å®šç¾©çš„æˆ¿é–“åˆ—è¡¨ (å‰3å€‹æˆ¿é–“)
        rooms_to_process = PREDEFINED_ROOMS[:3]

        # ä½¿ç”¨2025å¹´8æœˆçš„æ™‚é–“ç¯„åœ
        time_range = TIME_RANGES["2025_08"]
        search_start = time_range["start"]
        search_end = time_range["end"]

        print(f"æº–å‚™è™•ç† {len(rooms_to_process)} å€‹æˆ¿é–“")
        print(f"æ™‚é–“ç¯„åœ: {search_start} åˆ° {search_end}")

        results = []

        for i, room_info in enumerate(rooms_to_process, 1):
            print(f"\n[{i}/{len(rooms_to_process)}] è™•ç†æˆ¿é–“: {room_info.room}")

            try:
                dataset_id = await etl.process_room_data(
                    room_info=room_info,
                    search_start=search_start,
                    search_end=search_end,
                    window_days=ETL_CONFIG["default_window_days"]
                )

                results.append({
                    "room": room_info.room,
                    "status": "success",
                    "dataset_id": dataset_id
                })

                print(f"  âœ… æˆåŠŸï¼Œæ•¸æ“šé›† ID: {dataset_id}")

            except Exception as e:
                results.append({
                    "room": room_info.room,
                    "status": "failed",
                    "error": str(e)
                })

                print(f"  âŒ å¤±æ•—: {e}")

        # é¡¯ç¤ºè™•ç†çµæœæ‘˜è¦
        print("\n=== æ‰¹é‡è™•ç†çµæœæ‘˜è¦ ===")
        success_count = sum(1 for r in results if r["status"] == "success")
        failed_count = len(results) - success_count

        print(f"ç¸½è¨ˆ: {len(results)} å€‹æˆ¿é–“")
        print(f"æˆåŠŸ: {success_count} å€‹")
        print(f"å¤±æ•—: {failed_count} å€‹")

        if failed_count > 0:
            print("\nå¤±æ•—æˆ¿é–“è©³æƒ…:")
            for result in results:
                if result["status"] == "failed":
                    print(f"  - {result['room']}: {result['error']}")

    except Exception as e:
        print(f"âŒ æ‰¹é‡è™•ç†å¤±æ•—: {e}")

    finally:
        await etl.close_database()

async def example_data_quality_check():
    """
    ç¯„ä¾‹ï¼šæª¢æŸ¥æ•¸æ“šå“è³ªè€Œä¸åŸ·è¡Œå®Œæ•´çš„ ETL
    """
    print("\n=== æ•¸æ“šå“è³ªæª¢æŸ¥ç¯„ä¾‹ ===")

    database_url = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/pu_practice")
    etl = DataPreprocessingETL(database_url)

    try:
        await etl.connect_database()

        # é¸æ“‡ä¸€å€‹æˆ¿é–“é€²è¡Œå“è³ªæª¢æŸ¥
        room_info = PREDEFINED_ROOMS[0]  # ä½¿ç”¨ç¬¬ä¸€å€‹é å®šç¾©æˆ¿é–“

        # æª¢æŸ¥æœ€è¿‘30å¤©çš„æ•¸æ“šå“è³ª
        search_start = datetime(2025, 8, 1)
        search_end = datetime(2025, 8, 31)

        print(f"æª¢æŸ¥æˆ¿é–“: {room_info.room}")
        print(f"æ™‚é–“ç¯„åœ: {search_start} åˆ° {search_end}")

        # å°‹æ‰¾æœ€ä½³çª—å£ï¼ˆä¸åŸ·è¡Œå¾ŒçºŒæ­¥é©Ÿï¼‰
        try:
            best_start, best_end = await etl.find_golden_window(
                room_info, search_start, search_end, window_days=7
            )

            print(f"âœ… æ‰¾åˆ°æœ€ä½³æ•¸æ“šçª—å£:")
            print(f"  é–‹å§‹æ™‚é–“: {best_start}")
            print(f"  çµæŸæ™‚é–“: {best_end}")
            print(f"  çª—å£é•·åº¦: {(best_end - best_start).days} å¤©")

            # è©•ä¼°æ­¤çª—å£çš„è©³ç´°å“è³ªæŒ‡æ¨™
            quality_metrics = await etl._evaluate_data_quality(
                room_info, best_start, best_end
            )

            print(f"  æ•¸æ“šå®Œæ•´æ€§: {quality_metrics.completeness_ratio:.2%}")
            print(f"  ç¼ºå¤±æ™‚æ®µ: {quality_metrics.missing_periods}")

        except ValueError as e:
            print(f"âŒ æ‰¾ä¸åˆ°åˆé©çš„æ•¸æ“šçª—å£: {e}")

    except Exception as e:
        print(f"âŒ å“è³ªæª¢æŸ¥å¤±æ•—: {e}")

    finally:
        await etl.close_database()

def show_usage_instructions():
    """
    é¡¯ç¤ºä½¿ç”¨èªªæ˜
    """
    print("=== ETL ç³»çµ±ä½¿ç”¨èªªæ˜ ===")
    print()
    print("1. åŸ·è¡Œå‰æº–å‚™ï¼š")
    print("   - ç¢ºä¿è³‡æ–™åº«é€£æ¥æ­£å¸¸")
    print("   - è¨­ç½®ç’°å¢ƒè®Šæ•¸ DATABASE_URL")
    print("   - åŸ·è¡Œ Prisma é·ç§»å‰µå»ºæ–°è³‡æ–™è¡¨")
    print("   - ç¢ºä¿åŸå§‹é›»éŒ¶æ•¸æ“šå­˜åœ¨")
    print()
    print("2. ä¿®æ”¹é…ç½®ï¼š")
    print("   - ç·¨è¼¯ etl_config.py ä¸­çš„æˆ¿é–“è³‡è¨Š")
    print("   - èª¿æ•´ ETL_CONFIG ä¸­çš„è™•ç†åƒæ•¸")
    print("   - è¨­ç½®é©ç•¶çš„æ™‚é–“ç¯„åœ")
    print()
    print("3. åŸ·è¡Œæ–¹å¼ï¼š")
    print("   åŸºç¤åŠŸèƒ½:")
    print("   - å–®æˆ¿é–“è™•ç†: python etl_examples.py --single")
    print("   - æ‰¹é‡è™•ç†: python etl_examples.py --batch")
    print("   - å“è³ªæª¢æŸ¥: python etl_examples.py --check")
    print()
    print("   å¤šå°ºåº¦ç‰¹å¾µå·¥ç¨‹:")
    print("   - å¤šå°ºåº¦ç¯„ä¾‹: python etl_examples.py --multiscale")
    print("   - é…ç½®æ¯”è¼ƒ: python etl_examples.py --compare")
    print("   - å ´æ™¯ç¯„ä¾‹: python etl_examples.py --scenarios")
    print()
    print("4. æ³¨æ„äº‹é …ï¼š")
    print("   - é¦–æ¬¡åŸ·è¡Œå‰è«‹å…ˆé€²è¡Œå“è³ªæª¢æŸ¥")
    print("   - å»ºè­°å…ˆè™•ç†å°‘é‡æˆ¿é–“æ¸¬è©¦")
    print("   - ç•™æ„æ—¥èªŒè¼¸å‡ºä»¥ç›£æ§è™•ç†é€²åº¦")

# ========== å¤šå°ºåº¦ç‰¹å¾µå·¥ç¨‹ç¯„ä¾‹ ==========
async def etl_multiscale_features_example():
    """
    å±•ç¤ºå¤šå°ºåº¦ç‰¹å¾µå·¥ç¨‹çš„å®Œæ•´ä½¿ç”¨æµç¨‹
    """
    from data_preprocessing_etl_multiscale import MultiscaleETL
    from multiscale_config import get_multiscale_config, get_feature_list, calculate_feature_count

    print("=== å¤šå°ºåº¦ç‰¹å¾µå·¥ç¨‹ç¯„ä¾‹ ===")

    # é€£æ¥å­—ç¬¦ä¸²
    connection_string = "postgresql://username:password@localhost:5432/your_database"

    # æ¸¬è©¦ä¸åŒçš„å¤šå°ºåº¦é…ç½®
    configurations = ["full", "balanced", "short_only", "long_only"]

    for config_name in configurations:
        print(f"\n--- æ¸¬è©¦ {config_name.upper()} é…ç½® ---")

        # ç²å–é…ç½®
        config = get_multiscale_config(config_name)
        feature_count = calculate_feature_count(config)
        feature_list = get_feature_list(config_name)

        print(f"é…ç½®æ‘˜è¦:")
        print(f"  é•·æœŸçª—å£: {config['long_window_size']} åˆ†é˜")
        print(f"  çŸ­æœŸçª—å£: {config['short_window_size']} åˆ†é˜")
        print(f"  ç‰¹å¾µæ­¥é•·: {config['feature_step_size']} åˆ†é˜")
        print(f"  é æœŸç‰¹å¾µæ•¸: {feature_count['total_features']}")
        print(f"    - é•·æœŸç‰¹å¾µ: {feature_count['long_window_features']}")
        print(f"    - çŸ­æœŸç‰¹å¾µ: {feature_count['short_window_features']}")
        print(f"    - æ™‚é–“ç‰¹å¾µ: {feature_count['time_features']}")
        print(f"    - ç•¶å‰ç‰¹å¾µ: {feature_count['current_features']}")

        # é¡¯ç¤ºå‰10å€‹ç‰¹å¾µåç¨±
        print(f"  ç‰¹å¾µç¯„ä¾‹ (å‰10å€‹):")
        for i, feature_name in enumerate(feature_list[:10], 1):
            print(f"    {i:2d}. {feature_name}")

        if len(feature_list) > 10:
            print(f"    ... é‚„æœ‰ {len(feature_list) - 10} å€‹ç‰¹å¾µ")

        # å‰µå»ºETLå¯¦ä¾‹
        etl = MultiscaleETL(connection_string, config)

        # æˆ¿é–“è³‡è¨Š
        room_info = RoomInfo(
            room_name="A1",
            occupant_type=OccupantType.OFFICE,
            organization_id=1
        )

        # æ™‚é–“ç¯„åœï¼ˆç¤ºä¾‹ï¼‰
        start_time = datetime(2024, 1, 15, 9, 0)  # é€±ä¸€ä¸Šåˆ9é»
        end_time = datetime(2024, 1, 15, 18, 0)   # é€±ä¸€ä¸‹åˆ6é»

        try:
            print(f"  åŸ·è¡Œå¤šå°ºåº¦ç‰¹å¾µå·¥ç¨‹...")

            # åŸ·è¡Œè™•ç†ï¼ˆåƒ…å±•ç¤ºï¼Œå¯¦éš›ä½¿ç”¨æ™‚å–æ¶ˆè¨»é‡‹ï¼‰
            # result = await etl.process_room_data(
            #     room_info=room_info,
            #     start_time=start_time,
            #     end_time=end_time,
            #     source_anomaly_event_id=1001
            # )
            #
            # print(f"  è™•ç†çµæœ:")
            # print(f"    åŸå§‹æ¨£æœ¬æ•¸: {result['original_samples']}")
            # print(f"    å°é½Šå¾Œæ¨£æœ¬æ•¸: {result['aligned_samples']}")
            # print(f"    æœ€çµ‚ç‰¹å¾µæ¨£æœ¬æ•¸: {result['feature_samples']}")
            # print(f"    è™•ç†æ™‚é–“: {result['processing_time']:.2f} ç§’")

            print(f"  âœ… {config_name} é…ç½®è¨­å®šå®Œæˆ")

        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")

        print()

async def etl_feature_analysis_example():
    """
    å±•ç¤ºç‰¹å¾µåˆ†æå’Œæ¯”è¼ƒçš„ç¯„ä¾‹
    """
    from multiscale_config import FEATURE_PRESETS, calculate_feature_count

    print("\n=== å¤šå°ºåº¦ç‰¹å¾µé…ç½®æ¯”è¼ƒ ===")

    comparison_data = []

    for preset_name, preset_config in FEATURE_PRESETS.items():
        feature_count = calculate_feature_count(preset_config)

        comparison_data.append({
            "é…ç½®": preset_name,
            "é•·æœŸçª—å£": f"{preset_config['long_window_size']}åˆ†",
            "çŸ­æœŸçª—å£": f"{preset_config['short_window_size']}åˆ†",
            "æ­¥é•·": f"{preset_config['feature_step_size']}åˆ†",
            "é•·æœŸç‰¹å¾µ": feature_count['long_window_features'],
            "çŸ­æœŸç‰¹å¾µ": feature_count['short_window_features'],
            "æ™‚é–“ç‰¹å¾µ": feature_count['time_features'],
            "ç•¶å‰ç‰¹å¾µ": feature_count['current_features'],
            "ç¸½ç‰¹å¾µ": feature_count['total_features']
        })

    # æ‰“å°æ¯”è¼ƒè¡¨æ ¼
    print(f"{'é…ç½®':<12} {'é•·æœŸçª—å£':<8} {'çŸ­æœŸçª—å£':<8} {'æ­¥é•·':<6} {'é•·æœŸ':<4} {'çŸ­æœŸ':<4} {'æ™‚é–“':<4} {'ç•¶å‰':<4} {'ç¸½è¨ˆ':<4}")
    print("-" * 80)

    for data in comparison_data:
        print(f"{data['é…ç½®']:<12} {data['é•·æœŸçª—å£']:<8} {data['çŸ­æœŸçª—å£']:<8} {data['æ­¥é•·']:<6} "
              f"{data['é•·æœŸç‰¹å¾µ']:<4} {data['çŸ­æœŸç‰¹å¾µ']:<4} {data['æ™‚é–“ç‰¹å¾µ']:<4} {data['ç•¶å‰ç‰¹å¾µ']:<4} {data['ç¸½ç‰¹å¾µ']:<4}")

    print("\n=== ç‰¹å¾µé¸æ“‡å»ºè­° ===")
    print("ğŸ¯ FULL: å®Œæ•´ç‰¹å¾µé›†ï¼Œé©ç”¨æ–¼æ¨¡å‹è¨“ç·´å’Œå¯¦é©—")
    print("âš¡ BALANCED: å¹³è¡¡æ•ˆèƒ½èˆ‡ç²¾åº¦ï¼Œé©ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ")
    print("ğŸ” SHORT_ONLY: å°ˆæ³¨çŸ­æœŸæ¨¡å¼ï¼Œé©ç”¨æ–¼å³æ™‚ç•°å¸¸æª¢æ¸¬")
    print("ğŸ“ˆ LONG_ONLY: å°ˆæ³¨é•·æœŸè¶¨å‹¢ï¼Œé©ç”¨æ–¼è¶¨å‹¢åˆ†æ")
    print("ğŸ¯ HIGH_PRECISION: é«˜ç²¾åº¦æ¨¡å¼ï¼Œé©ç”¨æ–¼è©³ç´°åˆ†æ")

async def etl_real_world_scenario_example():
    """
    å±•ç¤ºçœŸå¯¦ä¸–ç•Œå ´æ™¯çš„ETLä½¿ç”¨ç¯„ä¾‹
    """
    from multiscale_config import get_multiscale_config

    print("\n=== çœŸå¯¦ä¸–ç•Œå ´æ™¯ç¯„ä¾‹ ===")

    # å ´æ™¯1: è¾¦å…¬å®¤ç•°å¸¸æª¢æ¸¬
    print("ğŸ“Š å ´æ™¯1: è¾¦å…¬å®¤ç”¨é›»ç•°å¸¸æª¢æ¸¬")
    print("  éœ€æ±‚: æª¢æ¸¬è¾¦å…¬æ™‚é–“å¤–çš„ç•°å¸¸ç”¨é›»")
    print("  å»ºè­°é…ç½®: BALANCED (å¹³è¡¡çŸ­æœŸæ³¢å‹•å’Œé•·æœŸè¶¨å‹¢)")
    print("  é—œéµç‰¹å¾µ: æ™‚é–“ç‰¹å¾µ + 60åˆ†é˜å¹³å‡åŠŸç‡ + 15åˆ†é˜æ¨™æº–å·®")

    config = get_multiscale_config("balanced")
    print(f"  çª—å£è¨­å®š: {config['long_window_size']}åˆ†é˜ / {config['short_window_size']}åˆ†é˜")

    # å ´æ™¯2: è¨­å‚™æ•…éšœé è­¦
    print("\nğŸ”§ å ´æ™¯2: è¨­å‚™æ•…éšœé è­¦")
    print("  éœ€æ±‚: æ•æ‰è¨­å‚™åŠŸç‡ç•°å¸¸æ³¢å‹•")
    print("  å»ºè­°é…ç½®: SHORT_ONLY (å°ˆæ³¨çŸ­æœŸè®ŠåŒ–)")
    print("  é—œéµç‰¹å¾µ: 15åˆ†é˜åŠŸç‡è®Šç•°æ•¸ + æœ€å¤§æœ€å°å€¼ç¯„åœ")

    config = get_multiscale_config("short_only")
    print(f"  çª—å£è¨­å®š: {config['short_window_size']}åˆ†é˜çŸ­æœŸåˆ†æ")

    # å ´æ™¯3: èƒ½è€—è¶¨å‹¢åˆ†æ
    print("\nğŸ“ˆ å ´æ™¯3: é•·æœŸèƒ½è€—è¶¨å‹¢åˆ†æ")
    print("  éœ€æ±‚: åˆ†ææœˆåº¦/å­£åº¦ç”¨é›»æ¨¡å¼")
    print("  å»ºè­°é…ç½®: LONG_ONLY (å°ˆæ³¨é•·æœŸè¶¨å‹¢)")
    print("  é—œéµç‰¹å¾µ: 60åˆ†é˜å¹³å‡åŠŸç‡ + æ™‚é–“ç‰¹å¾µ")

    config = get_multiscale_config("long_only")
    print(f"  çª—å£è¨­å®š: {config['long_window_size']}åˆ†é˜é•·æœŸåˆ†æ")

    # å ´æ™¯4: é«˜ç²¾åº¦ç ”ç©¶
    print("\nğŸ¯ å ´æ™¯4: é«˜ç²¾åº¦ç ”ç©¶åˆ†æ")
    print("  éœ€æ±‚: æœ€è©³ç´°çš„ç‰¹å¾µåˆ†æ")
    print("  å»ºè­°é…ç½®: HIGH_PRECISION (æœ€å¤§ç‰¹å¾µé›†)")
    print("  é—œéµç‰¹å¾µ: 2å°æ™‚é•·æœŸ + 5åˆ†é˜çŸ­æœŸ + å®Œæ•´çµ±è¨ˆç‰¹å¾µ")

    config = get_multiscale_config("high_precision")
    print(f"  çª—å£è¨­å®š: {config['long_window_size']}åˆ†é˜ / {config['short_window_size']}åˆ†é˜")

async def main():
    """
    ä¸»å‡½æ•¸ï¼šæ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸åŸ·è¡Œä¸åŒçš„ç¯„ä¾‹
    """
    import sys

    if len(sys.argv) < 2:
        show_usage_instructions()
        return

    command = sys.argv[1]

    if command == "--single":
        await example_single_room_processing()
    elif command == "--batch":
        await example_batch_processing()
    elif command == "--check":
        await example_data_quality_check()
    elif command == "--multiscale":
        await etl_multiscale_features_example()
    elif command == "--compare":
        await etl_feature_analysis_example()
    elif command == "--scenarios":
        await etl_real_world_scenario_example()
    elif command == "--help":
        show_usage_instructions()
    else:
        print(f"æœªçŸ¥å‘½ä»¤: {command}")
        print("ä½¿ç”¨ --help æŸ¥çœ‹ä½¿ç”¨èªªæ˜")

if __name__ == "__main__":
    asyncio.run(main())
