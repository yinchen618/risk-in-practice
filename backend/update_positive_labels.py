#!/usr/bin/env python3
"""
ğŸ¯ AnalysisDataset Positive Labels æ›´æ–°å·¥å…·

æ­¤è…³æœ¬ç”¨æ–¼ï¼š
1. é‡æ–°è¨ˆç®—ä¸¦æ›´æ–° AnalysisDataset çš„ positiveLabels æ•¸é‡
2. æª¢æŸ¥æ¨™è¨»å®Œæˆå¾Œçš„è³‡æ–™ä¸€è‡´æ€§
3. æä¾›è©³ç´°çš„æ›´æ–°å ±å‘Š

Author: AI Assistant
Date: 2025-08-27
"""

import sqlite3
import json
import logging
from datetime import datetime
from pathlib import Path

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('update_positive_labels.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_database_path():
    """ç²å–æ•¸æ“šåº«è·¯å¾‘"""
    # å˜—è©¦å¤šå€‹å¯èƒ½çš„è·¯å¾‘
    possible_paths = [
        Path(__file__).parent / "database" / "pu_practice.db",
        Path(__file__).parent / "database" / "prisma" / "pu_practice.db",
        Path(__file__).parent / "dev.db",
        Path(__file__).parent / "database" / "dev.db"
    ]

    for path in possible_paths:
        if path.exists():
            logger.info(f"æ‰¾åˆ°æ•¸æ“šåº«: {path}")
            return str(path)

    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›é»˜èªè·¯å¾‘
    default_path = Path(__file__).parent / "database" / "prisma" / "pu_practice.db"
    logger.warning(f"æœªæ‰¾åˆ°ç¾æœ‰æ•¸æ“šåº«ï¼Œä½¿ç”¨é»˜èªè·¯å¾‘: {default_path}")
    return str(default_path)

def update_analysis_dataset_positive_labels():
    """
    æ›´æ–° AnalysisDataset çš„ positiveLabels æ•¸é‡

    è¨ˆç®—æ–¹å¼ï¼š
    1. çµ±è¨ˆ AnalysisReadyData ä¸­ is_positive_label = true çš„è¨˜éŒ„æ•¸
    2. çµ±è¨ˆé—œè¯çš„ AnomalyEvent ä¸­ status = 'CONFIRMED_POSITIVE' çš„è¨˜éŒ„æ•¸
    3. å–å…©è€…çš„æœ€å¤§å€¼ä½œç‚º positiveLabels
    """
    db_path = get_database_path()

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        logger.info("ğŸš€ é–‹å§‹æ›´æ–° AnalysisDataset çš„ positiveLabels...")

        # ç²å–æ‰€æœ‰ AnalysisDataset
        cursor.execute("""
            SELECT id, name, total_records, positive_labels
            FROM analysis_datasets
            ORDER BY name
        """)

        datasets = cursor.fetchall()
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(datasets)} å€‹æ•¸æ“šé›†éœ€è¦æª¢æŸ¥")

        updated_count = 0
        total_positive_labels = 0

        for dataset_id, dataset_name, total_records, current_positive_labels in datasets:
            logger.info(f"\nğŸ” æª¢æŸ¥æ•¸æ“šé›†: {dataset_name} (ID: {dataset_id})")

            # æ–¹æ³•1: çµ±è¨ˆ AnalysisReadyData ä¸­çš„æ­£æ¨™ç±¤
            cursor.execute("""
                SELECT COUNT(*)
                FROM analysis_ready_data
                WHERE dataset_id = ? AND is_positive_label = 1
            """, (dataset_id,))

            positive_from_analysis_data = cursor.fetchone()[0]

            # æ–¹æ³•2: çµ±è¨ˆé—œè¯çš„ AnomalyEvent ä¸­ç¢ºèªç‚ºæ­£çš„æ•¸é‡
            cursor.execute("""
                SELECT COUNT(*)
                FROM anomaly_event
                WHERE dataset_id = ? AND status = 'CONFIRMED_POSITIVE'
            """, (dataset_id,))

            positive_from_anomaly_events = cursor.fetchone()[0]

            # æ–¹æ³•3: çµ±è¨ˆæ‰€æœ‰ç›¸é—œçš„ AnomalyEvent æ•¸é‡ï¼ˆæœªæ¨™è¨»çš„ï¼‰
            cursor.execute("""
                SELECT COUNT(*)
                FROM anomaly_event
                WHERE dataset_id = ?
            """, (dataset_id,))

            total_anomaly_events = cursor.fetchone()[0]

            # è¨ˆç®—æ–°çš„ positiveLabels å€¼
            # å„ªå…ˆä½¿ç”¨å·²ç¢ºèªçš„ç•°å¸¸äº‹ä»¶æ•¸é‡ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨åˆ†ææ•¸æ“šä¸­çš„æ¨™ç±¤
            new_positive_labels = max(positive_from_analysis_data, positive_from_anomaly_events)

            logger.info(f"   ğŸ“ˆ åˆ†ææ•¸æ“šä¸­çš„æ­£æ¨™ç±¤: {positive_from_analysis_data}")
            logger.info(f"   âœ… ç¢ºèªçš„ç•°å¸¸äº‹ä»¶: {positive_from_anomaly_events}")
            logger.info(f"   ğŸ“‹ ç¸½ç•°å¸¸äº‹ä»¶: {total_anomaly_events}")
            logger.info(f"   ğŸ¯ ç•¶å‰ positiveLabels: {current_positive_labels}")
            logger.info(f"   ğŸ†• æ–°çš„ positiveLabels: {new_positive_labels}")

            # å¦‚æœéœ€è¦æ›´æ–°
            if new_positive_labels != current_positive_labels:
                cursor.execute("""
                    UPDATE analysis_datasets
                    SET positive_labels = ?
                    WHERE id = ?
                """, (new_positive_labels, dataset_id))

                logger.info(f"   âœ… å·²æ›´æ–°: {current_positive_labels} â†’ {new_positive_labels}")
                updated_count += 1
            else:
                logger.info(f"   â„¹ï¸  ç„¡éœ€æ›´æ–°")

            total_positive_labels += new_positive_labels

        # æäº¤æ›´æ”¹
        conn.commit()

        # ç¸½çµå ±å‘Š
        logger.info(f"\nğŸ‰ æ›´æ–°å®Œæˆ!")
        logger.info(f"ğŸ“Š ç¸½æ•¸æ“šé›†æ•¸é‡: {len(datasets)}")
        logger.info(f"ğŸ”„ å·²æ›´æ–°æ•¸æ“šé›†: {updated_count}")
        logger.info(f"âœ… ç¸½æ­£æ¨™ç±¤æ•¸: {total_positive_labels}")

        return True

    except sqlite3.Error as e:
        logger.error(f"âŒ æ•¸æ“šåº«éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
        return False
    finally:
        if conn:
            conn.close()

def check_labeling_consistency():
    """
    æª¢æŸ¥æ¨™è¨»å®Œæˆå¾Œçš„è³‡æ–™ä¸€è‡´æ€§

    æª¢æŸ¥é …ç›®ï¼š
    1. ExperimentRun çš„å€™é¸æ•¸èˆ‡å¯¦éš› AnomalyEvent æ•¸é‡æ˜¯å¦ä¸€è‡´
    2. ExperimentRun çš„ positive_label_count èˆ‡ç¢ºèªçš„ç•°å¸¸äº‹ä»¶æ•¸æ˜¯å¦ä¸€è‡´
    3. AnalysisDataset çš„ positiveLabels èˆ‡ç›¸é—œ AnomalyEvent æ•¸é‡æ˜¯å¦ä¸€è‡´
    """
    db_path = get_database_path()

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        logger.info("\nğŸ” é–‹å§‹æª¢æŸ¥æ¨™è¨»ä¸€è‡´æ€§...")

        # æª¢æŸ¥ ExperimentRun çš„ä¸€è‡´æ€§
        cursor.execute("""
            SELECT
                er.id,
                er.name,
                er.status,
                er.candidate_count,
                er.positive_label_count,
                er.negative_label_count,
                COUNT(ae.id) as actual_anomaly_events,
                SUM(CASE WHEN ae.status = 'CONFIRMED_POSITIVE' THEN 1 ELSE 0 END) as confirmed_positive,
                SUM(CASE WHEN ae.status = 'REJECTED_NORMAL' THEN 1 ELSE 0 END) as rejected_normal,
                SUM(CASE WHEN ae.status = 'UNREVIEWED' THEN 1 ELSE 0 END) as unreviewed
            FROM experiment_run er
            LEFT JOIN anomaly_event ae ON er.id = ae.experiment_run_id
            WHERE er.status IN ('LABELING', 'COMPLETED')
            GROUP BY er.id, er.name, er.status, er.candidate_count, er.positive_label_count, er.negative_label_count
            ORDER BY er.created_at DESC
        """)

        experiments = cursor.fetchall()

        logger.info(f"ğŸ“‹ æª¢æŸ¥ {len(experiments)} å€‹å¯¦é©—çš„ä¸€è‡´æ€§...")

        inconsistent_experiments = 0

        for exp in experiments:
            (exp_id, exp_name, status, candidate_count, positive_count, negative_count,
             actual_events, confirmed_positive, rejected_normal, unreviewed) = exp

            logger.info(f"\nğŸ§ª å¯¦é©—: {exp_name} ({status})")
            logger.info(f"   ID: {exp_id}")
            logger.info(f"   ğŸ“Š è¨˜éŒ„çš„å€™é¸æ•¸: {candidate_count}")
            logger.info(f"   ğŸ“Š å¯¦éš›ç•°å¸¸äº‹ä»¶: {actual_events}")
            logger.info(f"   âœ… ç¢ºèªæ­£æ¨™ç±¤: {confirmed_positive} (è¨˜éŒ„: {positive_count})")
            logger.info(f"   âŒ æ‹’çµ•è² æ¨™ç±¤: {rejected_normal} (è¨˜éŒ„: {negative_count})")
            logger.info(f"   â³ æœªå¯©æŸ¥: {unreviewed}")

            # æª¢æŸ¥ä¸ä¸€è‡´æ€§
            issues = []

            if candidate_count != actual_events:
                issues.append(f"å€™é¸æ•¸ä¸ä¸€è‡´: è¨˜éŒ„ {candidate_count} vs å¯¦éš› {actual_events}")

            if positive_count != confirmed_positive:
                issues.append(f"æ­£æ¨™ç±¤æ•¸ä¸ä¸€è‡´: è¨˜éŒ„ {positive_count} vs å¯¦éš› {confirmed_positive}")

            if negative_count != rejected_normal:
                issues.append(f"è² æ¨™ç±¤æ•¸ä¸ä¸€è‡´: è¨˜éŒ„ {negative_count} vs å¯¦éš› {rejected_normal}")

            if issues:
                logger.warning(f"   âš ï¸  ç™¼ç¾ä¸ä¸€è‡´æ€§:")
                for issue in issues:
                    logger.warning(f"      - {issue}")
                inconsistent_experiments += 1

                # è‡ªå‹•ä¿®å¾©é¸é …
                logger.info(f"   ğŸ”§ è‡ªå‹•ä¿®å¾©å¯¦é©— {exp_name}...")
                cursor.execute("""
                    UPDATE experiment_run
                    SET
                        candidate_count = ?,
                        positive_label_count = ?,
                        negative_label_count = ?
                    WHERE id = ?
                """, (actual_events, confirmed_positive, rejected_normal, exp_id))
                logger.info(f"   âœ… å·²ä¿®å¾©")
            else:
                logger.info(f"   âœ… è³‡æ–™ä¸€è‡´")

        # æª¢æŸ¥ AnalysisDataset èˆ‡ AnomalyEvent çš„ä¸€è‡´æ€§
        logger.info(f"\nğŸ” æª¢æŸ¥ AnalysisDataset èˆ‡ AnomalyEvent çš„ä¸€è‡´æ€§...")

        cursor.execute("""
            SELECT
                ad.id,
                ad.name,
                ad.positive_labels,
                COUNT(ae.id) as total_anomaly_events,
                SUM(CASE WHEN ae.status = 'CONFIRMED_POSITIVE' THEN 1 ELSE 0 END) as confirmed_positive_events
            FROM analysis_datasets ad
            LEFT JOIN anomaly_event ae ON ad.id = ae.dataset_id
            GROUP BY ad.id, ad.name, ad.positive_labels
            ORDER BY ad.name
        """)

        dataset_consistency = cursor.fetchall()
        inconsistent_datasets = 0

        for dataset in dataset_consistency:
            (dataset_id, dataset_name, recorded_positive, total_events, confirmed_positive) = dataset

            logger.info(f"ğŸ“¦ æ•¸æ“šé›†: {dataset_name}")
            logger.info(f"   è¨˜éŒ„çš„æ­£æ¨™ç±¤: {recorded_positive}")
            logger.info(f"   ç¸½ç•°å¸¸äº‹ä»¶: {total_events}")
            logger.info(f"   ç¢ºèªçš„æ­£æ¨™ç±¤: {confirmed_positive}")

            if recorded_positive != confirmed_positive and confirmed_positive > 0:
                logger.warning(f"   âš ï¸  æ­£æ¨™ç±¤æ•¸ä¸ä¸€è‡´: è¨˜éŒ„ {recorded_positive} vs ç¢ºèª {confirmed_positive}")
                inconsistent_datasets += 1
            else:
                logger.info(f"   âœ… ä¸€è‡´")

        # æäº¤ä¿®å¾©
        conn.commit()

        # ç¸½çµ
        logger.info(f"\nğŸ“‹ ä¸€è‡´æ€§æª¢æŸ¥å®Œæˆ!")
        logger.info(f"âŒ ä¸ä¸€è‡´çš„å¯¦é©—: {inconsistent_experiments}/{len(experiments)}")
        logger.info(f"âŒ ä¸ä¸€è‡´çš„æ•¸æ“šé›†: {inconsistent_datasets}/{len(dataset_consistency)}")

        if inconsistent_experiments == 0 and inconsistent_datasets == 0:
            logger.info("ğŸ‰ æ‰€æœ‰è³‡æ–™éƒ½æ˜¯ä¸€è‡´çš„!")
        else:
            logger.info("ğŸ”§ å·²è‡ªå‹•ä¿®å¾©ç™¼ç¾çš„ä¸ä¸€è‡´æ€§")

        return True

    except sqlite3.Error as e:
        logger.error(f"âŒ æ•¸æ“šåº«éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
        return False
    finally:
        if conn:
            conn.close()

def generate_summary_report():
    """ç”Ÿæˆè©³ç´°çš„æ‘˜è¦å ±å‘Š"""
    db_path = get_database_path()

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        logger.info("\nğŸ“Š ç”Ÿæˆæ‘˜è¦å ±å‘Š...")

        # ç¸½é«”çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM analysis_datasets")
        total_datasets = cursor.fetchone()[0]

        cursor.execute("SELECT SUM(total_records) FROM analysis_datasets")
        total_records = cursor.fetchone()[0] or 0

        cursor.execute("SELECT SUM(positive_labels) FROM analysis_datasets")
        total_positive_labels = cursor.fetchone()[0] or 0

        cursor.execute("SELECT COUNT(*) FROM experiment_run")
        total_experiments = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM anomaly_event")
        total_anomaly_events = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM anomaly_event WHERE status = 'CONFIRMED_POSITIVE'")
        confirmed_positive = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM anomaly_event WHERE status = 'REJECTED_NORMAL'")
        rejected_normal = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM anomaly_event WHERE status = 'UNREVIEWED'")
        unreviewed = cursor.fetchone()[0]

        # ç”Ÿæˆå ±å‘Š
        report = f"""
ğŸ¯ ===============================================
ğŸ“Š AnalysisDataset Positive Labels æ›´æ–°å ±å‘Š
ğŸ“… ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ===============================================

ğŸ“ˆ ç¸½é«”çµ±è¨ˆ:
   ğŸ“¦ ç¸½æ•¸æ“šé›†æ•¸é‡: {total_datasets:,}
   ğŸ“‹ ç¸½è¨˜éŒ„æ•¸é‡: {total_records:,}
   âœ… ç¸½æ­£æ¨™ç±¤æ•¸: {total_positive_labels:,}
   ğŸ§ª ç¸½å¯¦é©—æ•¸: {total_experiments:,}
   âš¡ ç¸½ç•°å¸¸äº‹ä»¶: {total_anomaly_events:,}

ğŸ·ï¸ æ¨™è¨»ç‹€æ…‹çµ±è¨ˆ:
   âœ… å·²ç¢ºèªæ­£æ¨™ç±¤: {confirmed_positive:,}
   âŒ å·²æ‹’çµ•è² æ¨™ç±¤: {rejected_normal:,}
   â³ å¾…å¯©æŸ¥: {unreviewed:,}

ğŸ“Š æ¨™è¨»å®Œæˆç‡: {((confirmed_positive + rejected_normal) / max(total_anomaly_events, 1) * 100):.1f}%
âœ… æ­£æ¨™ç±¤æ¯”ä¾‹: {(confirmed_positive / max(total_anomaly_events, 1) * 100):.1f}%

ğŸ¯ ===============================================
        """

        logger.info(report)

        # ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶
        report_file = f"positive_labels_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        return True

    except sqlite3.Error as e:
        logger.error(f"âŒ æ•¸æ“šåº«éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
        return False
    finally:
        if conn:
            conn.close()

def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹ AnalysisDataset Positive Labels æ›´æ–°ç¨‹åº...")

    try:
        # 1. æ›´æ–° AnalysisDataset çš„ positiveLabels
        if not update_analysis_dataset_positive_labels():
            logger.error("âŒ æ›´æ–° positiveLabels å¤±æ•—")
            return False

        # 2. æª¢æŸ¥æ¨™è¨»ä¸€è‡´æ€§
        if not check_labeling_consistency():
            logger.error("âŒ æª¢æŸ¥ä¸€è‡´æ€§å¤±æ•—")
            return False

        # 3. ç”Ÿæˆæ‘˜è¦å ±å‘Š
        if not generate_summary_report():
            logger.error("âŒ ç”Ÿæˆå ±å‘Šå¤±æ•—")
            return False

        logger.info("ğŸ‰ æ‰€æœ‰ä»»å‹™å·²å®Œæˆ!")
        return True

    except Exception as e:
        logger.error(f"âŒ ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
