#!/usr/bin/env python3
"""
ERM Baseline è¶…åƒæ•¸æœç´¢è…³æœ¬
è‡ªå‹•è¨“ç·´å¤šå€‹æ¨¡å‹ä¸¦æ‰¾å‡ºæœ€ä½³è¶…åƒæ•¸çµ„åˆ
"""

import requests
import json
import time
import uuid
from datetime import datetime
import sqlite3
import asyncio
from typing import Dict, List, Tuple, Optional

# API é…ç½®
API_BASE = "https://weakrisk.yinchen.tw/api/v2"

class ERMBaselineHyperparameterSearch:
    def __init__(self):
        self.results = []
        self.best_model = None
        self.best_f1_score = 0.0

    def get_experiment_runs(self) -> List[Dict]:
        """ç²å–å¯ç”¨çš„å¯¦é©—é‹è¡Œ"""
        try:
            response = requests.get(f"{API_BASE}/experiment-runs")
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ ç„¡æ³•ç²å–å¯¦é©—é‹è¡Œ: {response.status_code}")
                return []
        except Exception as e:
            print(f"âŒ ç²å–å¯¦é©—é‹è¡Œæ™‚å‡ºéŒ¯: {e}")
            return []

    def get_analysis_datasets(self) -> List[Dict]:
        """ç²å–å¯ç”¨çš„æ•¸æ“šé›†"""
        try:
            response = requests.get(f"{API_BASE}/analysis-datasets")
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ ç„¡æ³•ç²å–æ•¸æ“šé›†: {response.status_code}")
                return []
        except Exception as e:
            print(f"âŒ ç²å–æ•¸æ“šé›†æ™‚å‡ºéŒ¯: {e}")
            return []

    def generate_hyperparameter_configs(self) -> List[Dict]:
        """ç”Ÿæˆ10çµ„ä¸åŒçš„è¶…åƒæ•¸é…ç½®"""
        configs = [
            # Config 1: åŸºç¤é…ç½® - å°æ¨¡å‹ï¼Œå¿«é€Ÿè¨“ç·´
            {
                "name": "Config_1_Small_Fast",
                "modelType": "LSTM",
                "hiddenSize": 32,
                "numLayers": 1,
                "dropout": 0.2,
                "windowSize": 10,
                "learningRate": 0.001,
                "batchSize": 32,
                "epochs": 50,
                "classPrior": 0.1,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.001,
                "earlyStopping": True,
                "patience": 10,
                "learningRateScheduler": "none"
            },
            # Config 2: ä¸­ç­‰æ¨¡å‹ - å¹³è¡¡é…ç½®
            {
                "name": "Config_2_Medium_Balanced",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 15,
                "learningRate": 0.0005,
                "batchSize": 64,
                "epochs": 80,
                "classPrior": 0.15,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0005,
                "earlyStopping": True,
                "patience": 15,
                "learningRateScheduler": "step"
            },
            # Config 3: å¤§æ¨¡å‹ - é«˜å®¹é‡
            {
                "name": "Config_3_Large_Capacity",
                "modelType": "LSTM",
                "hiddenSize": 128,
                "numLayers": 3,
                "dropout": 0.4,
                "windowSize": 20,
                "learningRate": 0.0003,
                "batchSize": 128,
                "epochs": 100,
                "classPrior": 0.2,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0001,
                "earlyStopping": True,
                "patience": 20,
                "learningRateScheduler": "cosine"
            },
            # Config 4: ä½å­¸ç¿’ç‡ - ç©©å®šè¨“ç·´
            {
                "name": "Config_4_Low_LR_Stable",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.25,
                "windowSize": 12,
                "learningRate": 0.0001,
                "batchSize": 64,
                "epochs": 120,
                "classPrior": 0.12,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.001,
                "earlyStopping": True,
                "patience": 25,
                "learningRateScheduler": "none"
            },
            # Config 5: é«˜ Dropout - é˜²æ­¢éæ“¬åˆ
            {
                "name": "Config_5_High_Dropout",
                "modelType": "LSTM",
                "hiddenSize": 96,
                "numLayers": 2,
                "dropout": 0.5,
                "windowSize": 18,
                "learningRate": 0.0008,
                "batchSize": 32,
                "epochs": 80,
                "classPrior": 0.18,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0008,
                "earlyStopping": True,
                "patience": 12,
                "learningRateScheduler": "step"
            },
            # Config 6: å¤§æ‰¹æ¬¡ - ç©©å®šæ¢¯åº¦
            {
                "name": "Config_6_Large_Batch",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 15,
                "learningRate": 0.002,  # å¤§æ‰¹æ¬¡é…åˆé«˜å­¸ç¿’ç‡
                "batchSize": 256,
                "epochs": 60,
                "classPrior": 0.15,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0003,
                "earlyStopping": True,
                "patience": 15,
                "learningRateScheduler": "none"
            },
            # Config 7: SGD å„ªåŒ–å™¨
            {
                "name": "Config_7_SGD_Momentum",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 15,
                "learningRate": 0.01,  # SGD é€šå¸¸éœ€è¦æ›´é«˜å­¸ç¿’ç‡
                "batchSize": 64,
                "epochs": 100,
                "classPrior": 0.15,
                "activationFunction": "relu",
                "optimizer": "sgd",
                "l2Regularization": 0.0005,
                "earlyStopping": True,
                "patience": 20,
                "learningRateScheduler": "step"
            },
            # Config 8: å°çª—å£ - ç´°ç²’åº¦ç‰¹å¾µ
            {
                "name": "Config_8_Small_Window",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 5,
                "learningRate": 0.001,
                "batchSize": 64,
                "epochs": 80,
                "classPrior": 0.15,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0005,
                "earlyStopping": True,
                "patience": 15,
                "learningRateScheduler": "none"
            },
            # Config 9: å¤§çª—å£ - é•·æœŸä¾è³´
            {
                "name": "Config_9_Large_Window",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 30,
                "learningRate": 0.0005,
                "batchSize": 64,
                "epochs": 80,
                "classPrior": 0.15,
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0005,
                "earlyStopping": True,
                "patience": 15,
                "learningRateScheduler": "none"
            },
            # Config 10: é«˜ Class Prior - æ›´å¤šæ­£æ¨£æœ¬å‡è¨­
            {
                "name": "Config_10_High_Prior",
                "modelType": "LSTM",
                "hiddenSize": 64,
                "numLayers": 2,
                "dropout": 0.3,
                "windowSize": 15,
                "learningRate": 0.0008,
                "batchSize": 64,
                "epochs": 80,
                "classPrior": 0.3,  # å‡è¨­ 30% çš„æœªæ¨™è¨˜æ¨£æœ¬ç‚ºæ­£æ¨£æœ¬
                "activationFunction": "relu",
                "optimizer": "adam",
                "l2Regularization": 0.0005,
                "earlyStopping": True,
                "patience": 15,
                "learningRateScheduler": "none"
            }
        ]

        return configs

    def start_training_job(self, experiment_run_id: str, config: Dict) -> Optional[Dict]:
        """é–‹å§‹è¨“ç·´ä½œæ¥­"""
        # ç”Ÿæˆå°ç£æ™‚é–“çš„æ¨¡å‹åç¨±
        taiwan_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        model_name = f"ERM_BASELINE_{config['name']}_{taiwan_time}"

        # æ•¸æ“šæºé…ç½® - ä½¿ç”¨æ¨™æº–åˆ†å‰²
        data_source_config = {
            "trainRatio": 70,
            "validationRatio": 20,
            "testRatio": 10,
            "timeRange": "all",
            "positiveDataSourceIds": [],  # æœƒç”±å¾Œç«¯è‡ªå‹•å¡«å……
            "unlabeledDataSourceIds": []  # æœƒç”±å¾Œç«¯è‡ªå‹•å¡«å……
        }

        payload = {
            "name": model_name,
            "scenario_type": "ERM_BASELINE",
            "experimentRunId": experiment_run_id,
            "modelConfig": json.dumps(config),
            "dataSourceConfig": json.dumps(data_source_config)
        }

        try:
            print(f"ğŸš€ é–‹å§‹è¨“ç·´: {config['name']}")
            print(f"   ğŸ“‹ æ¨¡å‹åç¨±: {model_name}")
            print(f"   ğŸ§  Hidden Size: {config['hiddenSize']}, Layers: {config['numLayers']}")
            print(f"   ğŸ“Š Window Size: {config['windowSize']}, Batch Size: {config['batchSize']}")
            print(f"   ğŸ“ˆ Learning Rate: {config['learningRate']}, Optimizer: {config['optimizer']}")

            response = requests.post(f"{API_BASE}/trained-models", json=payload)

            if response.status_code == 200 or response.status_code == 201:
                result = response.json()
                print(f"   âœ… è¨“ç·´ä½œæ¥­å·²é–‹å§‹: {result.get('jobId', 'Unknown')}")
                return result
            else:
                print(f"   âŒ è¨“ç·´è«‹æ±‚å¤±æ•—: {response.status_code}")
                print(f"   ğŸ“ éŒ¯èª¤è©³æƒ…: {response.text}")
                return None

        except Exception as e:
            print(f"   âŒ è¨“ç·´è«‹æ±‚ç•°å¸¸: {e}")
            return None

    def wait_for_training_completion(self, job_id: str, timeout_minutes: int = 20) -> bool:
        """ç­‰å¾…è¨“ç·´å®Œæˆ"""
        start_time = time.time()
        timeout_seconds = timeout_minutes * 60
        check_interval = 15  # æ¯15ç§’æª¢æŸ¥ä¸€æ¬¡

        print(f"   â³ ç­‰å¾…è¨“ç·´å®Œæˆ (æœ€é•·ç­‰å¾… {timeout_minutes} åˆ†é˜)...")

        # ç¬¬ä¸€æ¬¡å˜—è©¦ç›´æ¥æŸ¥æ‰¾ job_id
        attempts = 0
        while time.time() - start_time < timeout_seconds:
            try:
                # æŸ¥è©¢è¨“ç·´ç‹€æ…‹
                response = requests.get(f"{API_BASE}/trained-models")
                if response.status_code == 200:
                    models = response.json()

                    # æ–¹æ³•1: æ‰¾åˆ°å°æ‡‰çš„ job_id
                    target_model = None
                    for model in models:
                        model_job_id = model.get('jobId') or model.get('job_id')
                        if model_job_id == job_id:
                            target_model = model
                            break

                    # æ–¹æ³•2: å¦‚æœæ‰¾ä¸åˆ° job_idï¼Œå˜—è©¦ç”¨æœ€è¿‘å‰µå»ºçš„æ¨¡å‹
                    if not target_model and attempts < 5:
                        # æŒ‰å‰µå»ºæ™‚é–“æ’åºï¼Œæ‰¾æœ€æ–°çš„ RUNNING æˆ– PENDING æ¨¡å‹
                        for model in sorted(models, key=lambda x: x.get('createdAt', ''), reverse=True):
                            status = model.get('status', '').upper()
                            if status in ['RUNNING', 'PENDING']:
                                target_model = model
                                print(f"   ğŸ” ä½¿ç”¨æœ€æ–°çš„é‹è¡Œä¸­æ¨¡å‹: {model.get('name', 'Unknown')}")
                                break

                    if target_model:
                        status = target_model.get('status', 'UNKNOWN').upper()
                        model_name = target_model.get('name', 'Unknown')

                        if status == 'COMPLETED':
                            print(f"   âœ… è¨“ç·´å®Œæˆ! æ¨¡å‹: {model_name}")
                            return True
                        elif status == 'FAILED':
                            print(f"   âŒ è¨“ç·´å¤±æ•—! æ¨¡å‹: {model_name}")
                            return False
                        else:
                            # é¡¯ç¤ºé€²åº¦
                            elapsed = int(time.time() - start_time)
                            print(f"   â³ è¨“ç·´ä¸­... (å·²ç­‰å¾… {elapsed}s, ç‹€æ…‹: {status}, æ¨¡å‹: {model_name})")
                            time.sleep(check_interval)
                    else:
                        attempts += 1
                        if attempts <= 3:
                            print(f"   ğŸ” æœç´¢ä¸­... (å˜—è©¦ {attempts}/3)")
                            time.sleep(5)
                        else:
                            print(f"   âš ï¸ æ‰¾ä¸åˆ°å°æ‡‰çš„è¨“ç·´ä½œæ¥­ (Job ID: {job_id})")
                            time.sleep(check_interval)
                else:
                    print(f"   âš ï¸ ç„¡æ³•æŸ¥è©¢æ¨¡å‹ç‹€æ…‹: {response.status_code}")
                    time.sleep(check_interval)

            except Exception as e:
                print(f"   âš ï¸ æŸ¥è©¢ç‹€æ…‹æ™‚å‡ºéŒ¯: {e}")
                time.sleep(check_interval)

        print(f"   â° ç­‰å¾…è¶…æ™‚ ({timeout_minutes} åˆ†é˜)")
        return False

    def get_model_performance(self, job_id: str) -> Optional[Dict]:
        """ç²å–æ¨¡å‹æ€§èƒ½æŒ‡æ¨™"""
        try:
            response = requests.get(f"{API_BASE}/trained-models")
            if response.status_code == 200:
                models = response.json()

                # æ–¹æ³•1: å˜—è©¦ç”¨ job_id æ‰¾åˆ°æ¨¡å‹
                target_model = None
                for model in models:
                    model_job_id = model.get('jobId') or model.get('job_id')
                    if model_job_id == job_id:
                        target_model = model
                        break

                # æ–¹æ³•2: å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨æœ€æ–°å®Œæˆçš„æ¨¡å‹
                if not target_model:
                    print(f"   ğŸ” æ‰¾ä¸åˆ°æŒ‡å®š Job IDï¼Œä½¿ç”¨æœ€æ–°å®Œæˆçš„æ¨¡å‹...")
                    completed_models = [m for m in models if m.get('status', '').upper() == 'COMPLETED']
                    if completed_models:
                        # æŒ‰å‰µå»ºæ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
                        target_model = sorted(completed_models, key=lambda x: x.get('createdAt', ''), reverse=True)[0]
                        print(f"   ğŸ“‹ ä½¿ç”¨æ¨¡å‹: {target_model.get('name', 'Unknown')}")

                if target_model:
                    # è§£æè¨“ç·´æŒ‡æ¨™
                    training_metrics = target_model.get('trainingMetrics')
                    if training_metrics:
                        if isinstance(training_metrics, str):
                            training_metrics = json.loads(training_metrics)

                        return {
                            'model_id': target_model.get('id'),
                            'model_name': target_model.get('name'),
                            'status': target_model.get('status'),
                            'final_test_f1_score': training_metrics.get('final_test_f1_score', 0.0),
                            'best_val_f1_score': training_metrics.get('best_val_f1_score', 0.0),
                            'final_test_precision': training_metrics.get('final_test_precision', 0.0),
                            'final_test_recall': training_metrics.get('final_test_recall', 0.0),
                            'training_time_seconds': training_metrics.get('training_time_seconds', 0),
                            'total_epochs_trained': training_metrics.get('total_epochs_trained', 0),
                            'early_stopped': training_metrics.get('early_stopped', False),
                            'training_metrics': training_metrics
                        }
                    else:
                        print(f"   âš ï¸ æ¨¡å‹ {target_model.get('name')} æ²’æœ‰è¨“ç·´æŒ‡æ¨™")
                        return None

                print(f"   âŒ æ‰¾ä¸åˆ°ä»»ä½•åŒ¹é…çš„æ¨¡å‹")
                return None
            else:
                print(f"âŒ ç„¡æ³•ç²å–æ¨¡å‹åˆ—è¡¨: {response.status_code}")
                return None

        except Exception as e:
            print(f"âŒ ç²å–æ¨¡å‹æ€§èƒ½æ™‚å‡ºéŒ¯: {e}")
            return None

    def run_hyperparameter_search(self):
        """åŸ·è¡Œè¶…åƒæ•¸æœç´¢"""
        print("ğŸ” ERM Baseline è¶…åƒæ•¸æœç´¢é–‹å§‹")
        print("=" * 80)

        # 1. ç²å–å¯¦é©—é‹è¡Œ
        print("ğŸ“‹ ç²å–å¯ç”¨çš„å¯¦é©—é‹è¡Œ...")
        experiment_runs = self.get_experiment_runs()

        if not experiment_runs:
            print("âŒ æ²’æœ‰å¯ç”¨çš„å¯¦é©—é‹è¡Œ")
            return

        # é¸æ“‡ç¬¬ä¸€å€‹ COMPLETED ç‹€æ…‹çš„å¯¦é©—é‹è¡Œ
        target_experiment = None
        for exp in experiment_runs:
            if exp.get('status') == 'COMPLETED':
                target_experiment = exp
                break

        if not target_experiment:
            print("âŒ æ²’æœ‰æ‰¾åˆ° COMPLETED ç‹€æ…‹çš„å¯¦é©—é‹è¡Œ")
            return

        experiment_run_id = target_experiment['id']
        print(f"âœ… ä½¿ç”¨å¯¦é©—é‹è¡Œ: {target_experiment['name']} (ID: {experiment_run_id})")

        # 2. ç”Ÿæˆè¶…åƒæ•¸é…ç½®
        print(f"\nğŸ§¬ ç”Ÿæˆè¶…åƒæ•¸é…ç½®...")
        configs = self.generate_hyperparameter_configs()
        print(f"âœ… ç”Ÿæˆäº† {len(configs)} çµ„è¶…åƒæ•¸é…ç½®")

        # 3. é€ä¸€è¨“ç·´å’Œè©•ä¼°
        print(f"\nğŸš€ é–‹å§‹è¶…åƒæ•¸æœç´¢ (ç¸½å…± {len(configs)} çµ„é…ç½®)")
        print("=" * 80)

        for i, config in enumerate(configs, 1):
            print(f"\nğŸ“Š é…ç½® {i}/{len(configs)}: {config['name']}")
            print("-" * 60)

            # é–‹å§‹è¨“ç·´
            training_result = self.start_training_job(experiment_run_id, config)

            if not training_result:
                print(f"   âŒ é…ç½® {i} è¨“ç·´å•Ÿå‹•å¤±æ•—ï¼Œè·³é")
                continue

            job_id = training_result.get('jobId')
            if not job_id:
                print(f"   âŒ é…ç½® {i} æ²’æœ‰ç²å¾— Job IDï¼Œè·³é")
                continue

            # ç­‰å¾…è¨“ç·´å®Œæˆ
            success = self.wait_for_training_completion(job_id, timeout_minutes=20)

            if not success:
                print(f"   âŒ é…ç½® {i} è¨“ç·´æœªèƒ½åœ¨æ™‚é™å…§å®Œæˆï¼Œè·³é")
                continue

            # ç²å–æ€§èƒ½æŒ‡æ¨™
            performance = self.get_model_performance(job_id)

            if performance:
                self.results.append({
                    'config_name': config['name'],
                    'config': config,
                    'performance': performance,
                    'job_id': job_id
                })

                f1_score = performance['final_test_f1_score']
                precision = performance['final_test_precision']
                recall = performance['final_test_recall']
                training_time = performance['training_time_seconds']
                epochs = performance['total_epochs_trained']

                print(f"   ğŸ“ˆ æ€§èƒ½çµæœ:")
                print(f"      ğŸ¯ Test F1 Score: {f1_score:.4f}")
                print(f"      ğŸ¯ Test Precision: {precision:.4f}")
                print(f"      ğŸ“Š Test Recall: {recall:.4f}")
                print(f"      â±ï¸ è¨“ç·´æ™‚é–“: {training_time:.1f}s ({training_time/60:.1f}min)")
                print(f"      ğŸ”„ è¨“ç·´è¼ªæ•¸: {epochs}")

                # æ›´æ–°æœ€ä½³æ¨¡å‹
                if f1_score > self.best_f1_score:
                    self.best_f1_score = f1_score
                    self.best_model = {
                        'config_name': config['name'],
                        'config': config,
                        'performance': performance,
                        'job_id': job_id
                    }
                    print(f"   ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹! (F1: {f1_score:.4f})")
            else:
                print(f"   âŒ é…ç½® {i} ç„¡æ³•ç²å–æ€§èƒ½æŒ‡æ¨™")

        # 4. ç¸½çµçµæœ
        self.print_final_results()

    def print_final_results(self):
        """æ‰“å°æœ€çµ‚çµæœ"""
        print("\n" + "=" * 80)
        print("ğŸ è¶…åƒæ•¸æœç´¢å®Œæˆ")
        print("=" * 80)

        if not self.results:
            print("âŒ æ²’æœ‰æˆåŠŸå®Œæˆçš„è¨“ç·´")
            return

        # æŒ‰ F1 åˆ†æ•¸æ’åº
        sorted_results = sorted(self.results, key=lambda x: x['performance']['final_test_f1_score'], reverse=True)

        print(f"ğŸ“Š å®Œæˆè¨“ç·´æ•¸é‡: {len(self.results)}/10")
        print(f"ğŸ† æœ€ä½³ F1 åˆ†æ•¸: {self.best_f1_score:.4f}")
        print(f"ğŸ¥‡ æœ€ä½³é…ç½®: {self.best_model['config_name'] if self.best_model else 'None'}")

        print("\nğŸ“ˆ æ‰€æœ‰çµæœæ’å:")
        print("-" * 80)
        print(f"{'æ’å':<4} {'é…ç½®åç¨±':<25} {'F1åˆ†æ•¸':<8} {'ç²¾ç¢ºåº¦':<8} {'å¬å›ç‡':<8} {'è¨“ç·´æ™‚é–“':<10}")
        print("-" * 80)

        for i, result in enumerate(sorted_results, 1):
            perf = result['performance']
            f1 = perf['final_test_f1_score']
            precision = perf['final_test_precision']
            recall = perf['final_test_recall']
            time_min = perf['training_time_seconds'] / 60

            print(f"{i:<4} {result['config_name']:<25} {f1:<8.4f} {precision:<8.4f} {recall:<8.4f} {time_min:<10.1f}")

        if self.best_model:
            print(f"\nğŸ¯ æœ€ä½³é…ç½®è©³ç´°ä¿¡æ¯:")
            print("-" * 40)
            best_config = self.best_model['config']
            for key, value in best_config.items():
                if key != 'name':
                    print(f"  {key}: {value}")

            print(f"\nğŸ“Š æœ€ä½³æ¨¡å‹æ€§èƒ½:")
            print("-" * 40)
            best_perf = self.best_model['performance']
            print(f"  Test F1 Score: {best_perf['final_test_f1_score']:.4f}")
            print(f"  Test Precision: {best_perf['final_test_precision']:.4f}")
            print(f"  Test Recall: {best_perf['final_test_recall']:.4f}")
            print(f"  Best Val F1: {best_perf['best_val_f1_score']:.4f}")
            print(f"  Training Time: {best_perf['training_time_seconds']:.1f}s")
            print(f"  Epochs Trained: {best_perf['total_epochs_trained']}")
            print(f"  Early Stopped: {best_perf['early_stopped']}")

        # ä¿å­˜çµæœåˆ°æ–‡ä»¶
        self.save_results_to_file()

    def save_results_to_file(self):
        """ä¿å­˜çµæœåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"hyperparameter_search_results_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump({
                    'search_timestamp': timestamp,
                    'total_configs_tested': len(self.results),
                    'best_f1_score': self.best_f1_score,
                    'best_model': self.best_model,
                    'all_results': self.results
                }, f, indent=2, ensure_ascii=False)

            print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {filename}")

        except Exception as e:
            print(f"\nâŒ ä¿å­˜çµæœå¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ ERM Baseline è¶…åƒæ•¸æœç´¢å·¥å…·")
    print("ç›®æ¨™: æ¸¬è©¦ 10 çµ„ä¸åŒçš„è¶…åƒæ•¸é…ç½®ï¼Œæ‰¾å‡ºæœ€ä½³çµ„åˆ")
    print("=" * 80)

    # æª¢æŸ¥å¾Œç«¯æœå‹™æ˜¯å¦å¯ç”¨
    try:
        response = requests.get(f"{API_BASE}/analysis-datasets", timeout=5)
        if response.status_code != 200:
            print(f"âŒ å¾Œç«¯æœå‹™ä¸å¯ç”¨ (ç‹€æ…‹ç¢¼: {response.status_code})")
            return
    except Exception as e:
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ°å¾Œç«¯æœå‹™: {e}")
        print("è«‹ç¢ºä¿å¾Œç«¯æœå‹™é‹è¡Œåœ¨ https://weakrisk.yinchen.tw")
        return

    # é–‹å§‹æœç´¢
    searcher = ERMBaselineHyperparameterSearch()
    searcher.run_hyperparameter_search()

if __name__ == "__main__":
    main()
