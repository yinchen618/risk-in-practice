# F1-Score ç›£æ§å¢å¼·åŠŸèƒ½å¯¦ç¾å ±å‘Š

## ğŸ“Š å¯¦ç¾æ¦‚è¿°

æˆ‘å€‘æˆåŠŸåœ°å°‡è¨“ç·´ç›£æ§ç³»çµ±å¾å–®ç´”çš„ `val_loss` ç›£æ§å‡ç´šç‚ºä»¥ **Validation F1-Score** ç‚ºæ ¸å¿ƒçš„ç›£æ§ç³»çµ±ï¼Œé€™ç‚º PU Learning æ¨¡å‹çš„åˆ†é¡æ€§èƒ½æä¾›äº†æ›´ç›´è§€å’Œå¯¦ç”¨çš„è¨ºæ–·èƒ½åŠ›ã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½ç‰¹é»

### 1. å¢å¼·çš„è¨“ç·´æ—¥èªŒæ ¼å¼
```
Epoch 1/100 - Train Loss: 0.123, Val Loss: 90.5, Val F1: 0.15
Epoch 2/100 - Train Loss: 0.101, Val Loss: 85.2, Val F1: 0.25 (New best model!)
Epoch 3/100 - Train Loss: 0.095, Val Loss: 86.1, Val F1: 0.24
```

- **Train Loss**: è¨“ç·´æå¤±ï¼Œåæ˜ æ¨¡å‹å­¸ç¿’é€²åº¦
- **Val Loss**: é©—è­‰æå¤±ï¼ŒPU Learning ä¸­é€šå¸¸è¼ƒé«˜
- **Val F1**: é©—è­‰ F1 åˆ†æ•¸ï¼Œ**ä¸»è¦ç›£æ§æŒ‡æ¨™**
- **New best model!**: ç•¶ F1 åˆ†æ•¸æ”¹å–„æ™‚çš„æ¨™è¨˜

### 2. F1-Score ç‚ºåŸºç¤çš„ Early Stopping
- **ç›£æ§ç›®æ¨™**: å¾ `val_loss` æ”¹ç‚º `val_f1_score`
- **è§¸ç™¼æ¢ä»¶**: F1 åˆ†æ•¸é€£çºŒ N å€‹ epochs ç„¡æ”¹å–„
- **å„ªé»**: ç›´æ¥å„ªåŒ–æˆ‘å€‘é—œå¿ƒçš„åˆ†é¡æ€§èƒ½ï¼Œè€Œéæå¤±å‡½æ•¸

### 3. æœ€ä½³æ¨¡å‹æª¢æŸ¥é»ä¿å­˜
- **ä¿å­˜æ¢ä»¶**: åŸºæ–¼æœ€ä½³ F1 åˆ†æ•¸ï¼ˆä¸æ˜¯æœ€ä½æå¤±ï¼‰
- **æ¨¡å‹é¸æ“‡**: ä¿è­‰æœ€çµ‚æ¨¡å‹å…·æœ‰æœ€ä½³åˆ†é¡æ€§èƒ½
- **æŒ‡æ¨™è¿½è¹¤**: å¯¦éš›è¿½è¹¤å’Œä½¿ç”¨è¨“ç·´éç¨‹ä¸­çš„æœ€ä½³ F1 åˆ†æ•¸

### 4. éšæ®µæ€§è¨“ç·´è¨ºæ–·
- **è¨ºæ–·é »ç‡**: æ¯ 25 epochs æä¾›è¨“ç·´ç‹€æ…‹åˆ†æ
- **ç‹€æ…‹åˆ†é¡**: improving / plateauing / declining
- **ç„¡æ”¹å–„è¨ˆæ•¸**: é¡¯ç¤ºé€£çºŒç„¡æ”¹å–„çš„ epochs æ•¸é‡

## ğŸ”§ æŠ€è¡“å¯¦ç¾è©³æƒ…

### æ ¸å¿ƒä¿®æ”¹æ–‡ä»¶
1. **`model_trainer.py`**: ä¸»è¦è¨“ç·´å¾ªç’°å’ŒæŒ‡æ¨™è¨ˆç®—
2. **`websocket_manager.py`**: WebSocket ç‹€æ…‹å»£æ’­ï¼ˆå·²æœ‰ï¼‰
3. **æ¸¬è©¦è…³æœ¬**: é©—è­‰åŠŸèƒ½çš„æ¨¡æ“¬æ¼”ç¤º

### é—œéµä»£ç¢¼è®Šæ›´

#### 1. è¨“ç·´å¾ªç’°æ›´æ–°
```python
# èˆŠç‰ˆï¼šåŸºæ–¼ val_accuracy
if val_accuracy > best_val_accuracy:
    best_val_accuracy = val_accuracy
    no_improvement_count = 0

# æ–°ç‰ˆï¼šåŸºæ–¼ val_f1_score
if val_f1_score > best_val_f1_score:
    best_val_f1_score = val_f1_score
    no_improvement_count = 0
    is_best_model = True
```

#### 2. æ—¥èªŒæ ¼å¼æ¨™æº–åŒ–
```python
best_indicator = " (New best model!)" if is_best_model else ""
await self._log(job_id, f"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.1f}, Val F1: {val_f1_score:.2f}{best_indicator}")
```

#### 3. æŒ‡æ¨™ç”Ÿæˆæ›´æ–°
```python
return {
    'final_train_loss': final_train_loss,
    'final_val_loss': final_val_loss, 
    'final_val_f1_score': final_val_f1_score,
    'best_val_f1_score': best_f1_from_training,  # ä½¿ç”¨å¯¦éš›æœ€ä½³å€¼
    'early_stopping_metric': 'val_f1_score',     # è¨˜éŒ„ç›£æ§æŒ‡æ¨™
    ...
}
```

## ğŸ“ˆ å¯¦éš›æ•ˆæœæ¼”ç¤º

### æ­£å¸¸è¨“ç·´éç¨‹
```
ğŸ§ª æ¸¬è©¦ F1-Score ç›£æ§åŠŸèƒ½
==================================================
ğŸ“Š ç›£æ§æŒ‡æ¨™: Train Loss, Val Loss, Val F1 Score
ğŸ¯ Early stopping ç›®æ¨™: Validation F1 Score (patience: 10)

Epoch 1/50 - Train Loss: 0.828, Val Loss: 1.5, Val F1: 0.18 (New best model!)
Epoch 2/50 - Train Loss: 0.931, Val Loss: 2.1, Val F1: 0.20 (New best model!)
...
Epoch 47/50 - Train Loss: 0.765, Val Loss: 1.6, Val F1: 0.64 (New best model!)
Epoch 50/50 - Train Loss: 0.813, Val Loss: 1.8, Val F1: 0.65 (New best model!)

âœ… Training completed after 50 epochs
ğŸ¯ Best validation F1 score: 0.654
```

### Early Stopping æ¼”ç¤º
```
ğŸ§ª æ¨¡æ“¬ F1-Score Early Stopping åŠŸèƒ½
==================================================
ğŸ“Š ç›£æ§æŒ‡æ¨™: Train Loss, Val Loss, Val F1 Score
ğŸ¯ Early stopping ç›®æ¨™: Validation F1 Score (patience: 8)

Epoch 31/100 - Train Loss: 0.714, Val Loss: 1.6, Val F1: 0.57 (New best model!)
Epoch 32/100 - Train Loss: 0.766, Val Loss: 1.5, Val F1: 0.55
...
Epoch 39/100 - Train Loss: 0.762, Val Loss: 1.7, Val F1: 0.52
ğŸ›‘ Early stopping triggered after 39 epochs (patience: 8) - No F1 improvement

ğŸ¯ Best validation F1 score: 0.570
```

## ğŸ¯ è¨ºæ–·èƒ½åŠ›æå‡

### 1. **åˆ†é¡æ€§èƒ½å¯è¦–åŒ–**
- ç›´æ¥è§€å¯Ÿ F1 åˆ†æ•¸è®ŠåŒ–è¶¨å‹¢
- è­˜åˆ¥æ¨¡å‹ä½•æ™‚é”åˆ°æœ€ä½³åˆ†é¡æ€§èƒ½
- å€åˆ†æå¤±æ”¹å–„èˆ‡åˆ†é¡æ€§èƒ½æ”¹å–„

### 2. **è¨“ç·´æ•ˆç‡å„ªåŒ–**
- F1-based Early Stopping é¿å…ç„¡æ•ˆè¨“ç·´
- ä¿å­˜çœŸæ­£çš„æœ€ä½³åˆ†é¡æ¨¡å‹
- æä¾›è¨“ç·´ç‹€æ…‹è¨ºæ–·

### 3. **PU Learning ç‰¹åŒ–**
- è€ƒæ…® PU Learning ä¸­ val_loss é€šå¸¸è¼ƒé«˜çš„ç‰¹é»
- F1 åˆ†æ•¸æ›´é©åˆè©•ä¼° PU Learning çš„åˆ†é¡æ•ˆæœ
- æä¾›ç¬¦åˆ PU Learning ç‰¹æ€§çš„æŒ‡æ¨™ç›£æ§

## ğŸš€ éƒ¨ç½²ç‹€æ…‹

- âœ… **å¾Œç«¯å¯¦ç¾**: å®Œæˆæ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½
- âœ… **æ¸¬è©¦é©—è­‰**: é€šéæ¨¡æ“¬æ¸¬è©¦é©—è­‰
- âœ… **æœå‹™é‹è¡Œ**: å¾Œç«¯æœå‹™ (ç«¯å£ 8000) å’Œå‰ç«¯æœå‹™ (ç«¯å£ 3002) æ­£å¸¸é‹è¡Œ
- âœ… **WebSocket æ”¯æŒ**: å¯¦æ™‚æ—¥èªŒå‚³è¼¸åŠŸèƒ½å®Œæ•´

## ğŸ“‹ ä½¿ç”¨å»ºè­°

1. **ç›£æ§é‡é»**: é—œæ³¨ Val F1 åˆ†æ•¸è€Œé Val Loss
2. **Early Stopping**: å»ºè­° patience è¨­ç½®ç‚º 10-15 epochs
3. **æ¨¡å‹é¸æ“‡**: å§‹çµ‚ä½¿ç”¨æœ€ä½³ F1 åˆ†æ•¸çš„æ¨¡å‹é€²è¡Œæ¨ç†
4. **è¨ºæ–·åˆ†æ**: åˆ©ç”¨éšæ®µæ€§è¨ºæ–·è­˜åˆ¥è¨“ç·´å•é¡Œ

é€™å€‹å¢å¼·çš„ç›£æ§ç³»çµ±ç‚ºæ‚¨æä¾›äº†è¨ºæ–·æ¨¡å‹è¡Œç‚ºçš„**æœ€å¼·å¤§çš„æ­¦å™¨**ï¼Œè®“æ‚¨èƒ½å¤ ç›´è§€åœ°äº†è§£æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šçš„åˆ†é¡èƒ½åŠ›è®ŠåŒ–ã€‚
